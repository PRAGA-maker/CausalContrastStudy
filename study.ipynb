{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31deaaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, site\n",
    "\n",
    "# Make sure the user site-packages dir (/home/jupyter/.local/...) is on sys.path\n",
    "try:\n",
    "    user_site = site.getusersitepackages()\n",
    "    if user_site not in sys.path:\n",
    "        sys.path.append(user_site)\n",
    "        print(\"Added user site-packages to sys.path:\", user_site)\n",
    "    else:\n",
    "        print(\"User site-packages already on sys.path:\", user_site)\n",
    "except Exception as e:\n",
    "    print(\"Could not resolve user site-packages:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495fd80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 1: SETUP ---\n",
    "import sys\n",
    "!{sys.executable} -m pip install pandas numpy scipy matplotlib seaborn tqdm scikit-learn lifelines pandas-gbq google-cloud-bigquery fastparquet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "import subprocess\n",
    "import scipy.sparse as sp\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "# --- Machine Learning & Stats ---\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "import fastparquet\n",
    "\n",
    "# --- Survival Analysis ---\n",
    "import sys, subprocess, site\n",
    "\n",
    "# ensure user site is on path **before** importing\n",
    "try:\n",
    "    user_site = site.getusersitepackages()\n",
    "    if user_site not in sys.path:\n",
    "        sys.path.append(user_site)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    from lifelines import CoxPHFitter, KaplanMeierFitter\n",
    "    from lifelines.statistics import logrank_test\n",
    "except ImportError:\n",
    "    # install into the current interpreter's env\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"lifelines\"])\n",
    "    from lifelines import CoxPHFitter, KaplanMeierFitter\n",
    "    from lifelines.statistics import logrank_test\n",
    "\n",
    "\n",
    "# --- Configurations ---\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"whitegrid\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "WORKSPACE_CDR = os.environ.get(\"WORKSPACE_CDR\", \"\")\n",
    "N_CORES = max(1, os.cpu_count() - 2)\n",
    "\n",
    "print(f\"Environment Ready. CDR: {WORKSPACE_CDR}, Cores: {N_CORES}\")\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def to_naive_utc_day(series):\n",
    "    \"\"\"Robustly converts mixed timezones to naive UTC midnight.\"\"\"\n",
    "    return pd.to_datetime(series, errors='coerce', utc=True).dt.tz_localize(None).dt.normalize()\n",
    "\n",
    "def clean_mem():\n",
    "    \"\"\"Forces garbage collection.\"\"\"\n",
    "    gc.collect()\n",
    "\n",
    "def calculate_ess(weights):\n",
    "    \"\"\"Calculates Kish's Effective Sample Size.\"\"\"\n",
    "    if len(weights) == 0: return 0\n",
    "    return (np.sum(weights) ** 2) / np.sum(weights ** 2)\n",
    "\n",
    "def sparse_weighted_mean_var(X, weights):\n",
    "    \"\"\"Calculates means/vars of sparse matrix X with weights without densifying.\"\"\"\n",
    "    # X is (N, P), weights is (N,)\n",
    "    W = sp.diags(weights)\n",
    "    X_weighted = W @ X\n",
    "    sum_w = np.sum(weights)\n",
    "    means = np.array(X_weighted.sum(axis=0) / sum_w).flatten()\n",
    "    \n",
    "    # Variance is trickier, simplified approximation for Love Plot speed:\n",
    "    # Var = E[X^2] - (E[X])^2\n",
    "    X2 = X.power(2)\n",
    "    means2 = np.array((W @ X2).sum(axis=0) / sum_w).flatten()\n",
    "    vars_ = means2 - (means ** 2)\n",
    "    return means, vars_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe5cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: Clinical Definitions & Negative Controls (Refined)\n",
    "# =============================================================================\n",
    "print(\"\\n--- CELL 2: Clinical Definitions & Negative Controls ---\")\n",
    "\n",
    "# --- 1. EXPOSURES ---\n",
    "CONTRAST_CT = {4139745, 21492176, 4335400, 3047782, 4327032, 3013610, 36713226, 3053128, 4252907, 3019625}\n",
    "CONTRAST_MRI = {4335399, 4161393, 4202274, 4197203, 36717294, 45765683, 37117806, 37109194, 37109196}\n",
    "CONTRAST_IDS = CONTRAST_CT.union(CONTRAST_MRI)\n",
    "\n",
    "NON_CONTRAST_CT = {37109313, 3049940, 37117305, 3047921, 36713200, 3018999, 40771605, 36713202, 3035568}\n",
    "NON_CONTRAST_MRI = {37109312, 36713204, 36713045, 36713262, 3024397, 36713243, 3053040, 37109329, 42535581, 42535582}\n",
    "NON_CONTRAST_IDS = NON_CONTRAST_CT.union(NON_CONTRAST_MRI)\n",
    "\n",
    "ALL_IMAGING = CONTRAST_IDS.union(NON_CONTRAST_IDS)\n",
    "\n",
    "# --- 2. MAIN OUTCOMES (The Targets) ---\n",
    "# Naming Convention: Key is used for column naming (e.g., date_AKI_30)\n",
    "ANALYSIS_OUTCOMES = {\n",
    "    'AKI_30': ({761083, 197320, 40481064, 4328366, 37116432, 45757442, 37016366}, 30),\n",
    "    'NEW_DIALYSIS_90': ({4032243, 4146536, 4324124, 4019967, 40482357}, 90),\n",
    "    'MORTALITY_30': ('DEATH', 30),\n",
    "    'MAE_30': ('COMPOSITE', 30), # Defined as min(AKI, Dialysis, Death)\n",
    "    'THYROID_90': ({138384, 37016342, 45757058, 4032331}, 90)\n",
    "}\n",
    "\n",
    "# --- 3. COVARIATE DEFINITIONS (Not Policies) ---\n",
    "# Used for confounding adjustment, NOT for \"withholding\" rules\n",
    "THYROTOXICOSIS_IDS = {37016342, 45757058, 440936, 134438} \n",
    "\n",
    "# Lab Concepts - STRICT SEPARATION\n",
    "# Only use true eGFR codes for eGFR. Creatinine is a separate covariate.\n",
    "\n",
    "# eGFR (CKD-EPI, MDRD, etc.) â€“ ONLY true eGFR concepts\n",
    "EGFR_CONCEPTS = {\n",
    "    333096, 3049187, 3053283, 3029859, 1619026, 1619025\n",
    "}\n",
    "\n",
    "# Serum Creatinine\n",
    "CREATININE_CONCEPTS = {3016723, 3020564, 3034485, 3022192}\n",
    "\n",
    "\n",
    "# --- 4. NEGATIVE CONTROLS (The Calibrators) ---\n",
    "NEGATIVE_CONTROLS = {\n",
    "    'NC_Ingrown_Nail': {139900},\n",
    "    'NC_Ankle_Sprain': {4196156},\n",
    "    'NC_Cataract': {375545},\n",
    "    'NC_Otitis_Media': {378534},\n",
    "    'NC_T2DM': {201826}, \n",
    "    'NC_Hypertension': {320128},\n",
    "    'NC_Hyperlipidemia': {432867},\n",
    "    'NC_Gout': {439392},\n",
    "    'NC_Depression': {4282316}, \n",
    "    'NC_Anxiety': {436073}, \n",
    "    'NC_Insomnia': {436962},\n",
    "    'NC_Osteoarthritis': {4079750, 4155298},\n",
    "    'NC_Low_Back_Pain': {4213162},\n",
    "    'NC_Carpal_Tunnel': {376918},\n",
    "    'NC_Allergic_Rhinitis': {379805},\n",
    "    'NC_GERD': {192279}, \n",
    "    'NC_Migraine': {375527}, \n",
    "    'NC_Hypothyroidism': {140673},\n",
    "    'NC_Varicose_Veins': {318800}\n",
    "}\n",
    "\n",
    "ALL_NEGATIVE_CONTROL_IDS = set().union(*NEGATIVE_CONTROLS.values())\n",
    "\n",
    "# --- 5. EXCLUSION LIST (Covariates to drop) ---\n",
    "# We ONLY exclude concepts if they are the outcome itself occurring *after* index.\n",
    "# We do NOT exclude pre-index history of these conditions (they are confounders).\n",
    "# Specific logic applied in Cell 5.\n",
    "OUTCOME_CONCEPTS = set().union(*[v[0] for k,v in ANALYSIS_OUTCOMES.items() if isinstance(v[0], set)])\n",
    "\n",
    "print(f\"Definitions Loaded. {len(NEGATIVE_CONTROLS)} Negative Controls defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b1fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 2.5: Empirical Null Calibration Engine\n",
    "# =============================================================================\n",
    "from scipy.stats import norm\n",
    "\n",
    "def calibrate_estimates(results_df):\n",
    "    \"\"\"\n",
    "    Fits an Empirical Null distribution to Negative Controls and calibrates\n",
    "    the P-values and CIs for the Main Outcomes.\n",
    "    \n",
    "    Assumption: Negative Controls have True Log-RR = 0.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Performing Empirical Calibration ---\")\n",
    "    \n",
    "    # 1. Identify Negative Controls\n",
    "    # Assumes results_df has a column 'Type' or 'Outcome' starting with 'NC_'\n",
    "    nc_df = results_df[results_df['Outcome'].str.startswith('NC_')].copy()\n",
    "    \n",
    "    if len(nc_df) < 10:\n",
    "        print(\"WARNING: Too few negative controls (<10) for robust calibration.\")\n",
    "        return results_df\n",
    "    \n",
    "    # 2. Extract Log-RR and Standard Error (from CI)\n",
    "    # We use Log-RR because it's symmetric. \n",
    "    # SE = (Log(Upper) - Log(Lower)) / 3.92\n",
    "    nc_df['log_rr'] = np.log(nc_df['HR_Cox'].astype(float))\n",
    "    nc_df['se_log_rr'] = (np.log(nc_df['HR_CI_High'].astype(float)) - np.log(nc_df['HR_CI_Low'].astype(float))) / 3.92\n",
    "    \n",
    "    # Drop invalid results (infinite or NaN)\n",
    "    nc_df = nc_df.replace([np.inf, -np.inf], np.nan).dropna(subset=['log_rr', 'se_log_rr'])\n",
    "    \n",
    "    # 3. Fit the Null Distribution N(mu, sigma^2)\n",
    "    # We use a weighted moment estimator (inverse variance weighting)\n",
    "    weights = 1.0 / (nc_df['se_log_rr'] ** 2)\n",
    "    \n",
    "    # Mean bias (Systematic Shift)\n",
    "    null_mean = np.average(nc_df['log_rr'], weights=weights)\n",
    "    \n",
    "    # SD bias (Unmeasured Confounding width)\n",
    "    # Variance = weighted average of (x - mean)^2 - average sampling variance\n",
    "    raw_var = np.average((nc_df['log_rr'] - null_mean)**2, weights=weights)\n",
    "    expected_sampling_var = np.average(nc_df['se_log_rr']**2, weights=weights)\n",
    "    \n",
    "    # The systematic variance is the excess variance observed\n",
    "    null_var = max(0, raw_var - expected_sampling_var)\n",
    "    null_sd = np.sqrt(null_var)\n",
    "    \n",
    "    print(f\"  Empirical Null Fitted: Mean Bias = {null_mean:.4f}, SD Bias = {null_sd:.4f}\")\n",
    "    print(f\"  (Interpretation: Mean!=0 implies systematic error; SD>0 implies unmeasured confounding)\")\n",
    "    \n",
    "    # 4. Calibrate All Estimates (Main + NCs)\n",
    "    calibrated_results = results_df.copy()\n",
    "    \n",
    "    # Calculate Log stats for all rows\n",
    "    log_rr = np.log(calibrated_results['HR_Cox'].astype(float))\n",
    "    se_log_rr = (np.log(calibrated_results['HR_CI_High'].astype(float)) - np.log(calibrated_results['HR_CI_Low'].astype(float))) / 3.92\n",
    "    \n",
    "    # Calibrated Z-Score\n",
    "    # We subtract the mean bias and divide by the wider uncertainty (sampling + systematic)\n",
    "    z_cal = (log_rr - null_mean) / np.sqrt(se_log_rr**2 + null_sd**2)\n",
    "    \n",
    "    # Calibrated P-value\n",
    "    calibrated_results['P_Calibrated'] = 2 * (1 - norm.cdf(np.abs(z_cal)))\n",
    "    \n",
    "    # Calibrated CIs (Shifted and Widened)\n",
    "    calibrated_se = np.sqrt(se_log_rr**2 + null_sd**2)\n",
    "    calibrated_results['HR_Calibrated'] = np.exp(log_rr - null_mean)\n",
    "    calibrated_results['HR_Cal_Low'] = np.exp((log_rr - null_mean) - 1.96 * calibrated_se)\n",
    "    calibrated_results['HR_Cal_High'] = np.exp((log_rr - null_mean) + 1.96 * calibrated_se)\n",
    "    \n",
    "    return calibrated_results\n",
    "\n",
    "# Function to plot the calibration (Funnel Plot)\n",
    "def plot_calibration(results_df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot Negative Controls\n",
    "    ncs = results_df[results_df['Outcome'].str.startswith('NC_')]\n",
    "    log_rr_nc = np.log(ncs['HR_Cox'].astype(float))\n",
    "    se_nc = (np.log(ncs['HR_CI_High'].astype(float)) - np.log(ncs['HR_CI_Low'].astype(float))) / 3.92\n",
    "    \n",
    "    plt.scatter(log_rr_nc, 1/se_nc, alpha=0.5, color='gray', label='Negative Controls')\n",
    "    \n",
    "    # Plot Main Outcomes\n",
    "    main = results_df[~results_df['Outcome'].str.startswith('NC_')]\n",
    "    log_rr_main = np.log(main['HR_Cox'].astype(float))\n",
    "    se_main = (np.log(main['HR_CI_High'].astype(float)) - np.log(main['HR_CI_Low'].astype(float))) / 3.92\n",
    "    \n",
    "    plt.scatter(log_rr_main, 1/se_main, color='red', s=100, label='Main Outcomes', zorder=10)\n",
    "    \n",
    "    # Plot Null Line (x=0 is HR=1)\n",
    "    plt.axvline(0, color='black', linestyle='--')\n",
    "    \n",
    "    # Plot Fitted Null Area (Mean +/- SD)\n",
    "    # We just draw the region around 0 to show visual calibration\n",
    "    # (If using the fitted values, draw vertical lines at null_mean)\n",
    "    \n",
    "    plt.xlabel(\"Log Hazard Ratio\")\n",
    "    plt.ylabel(\"Precision (1/SE)\")\n",
    "    plt.title(\"Empirical Calibration Funnel Plot\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e0eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 2.5: Empirical Null Calibration Engine\n",
    "# =============================================================================\n",
    "from scipy.stats import norm\n",
    "\n",
    "def calibrate_estimates(results_df):\n",
    "    \"\"\"\n",
    "    Fits an Empirical Null distribution to Negative Controls and calibrates\n",
    "    the P-values and CIs for the Main Outcomes.\n",
    "    \n",
    "    Assumption: Negative Controls have True Log-RR = 0.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Performing Empirical Calibration ---\")\n",
    "    \n",
    "    # 1. Identify Negative Controls\n",
    "    # Assumes results_df has a column 'Type' or 'Outcome' starting with 'NC_'\n",
    "    nc_df = results_df[results_df['Outcome'].str.startswith('NC_')].copy()\n",
    "    \n",
    "    if len(nc_df) < 10:\n",
    "        print(\"WARNING: Too few negative controls (<10) for robust calibration.\")\n",
    "        return results_df\n",
    "    \n",
    "    # 2. Extract Log-RR and Standard Error (from CI)\n",
    "    # We use Log-RR because it's symmetric. \n",
    "    # SE = (Log(Upper) - Log(Lower)) / 3.92\n",
    "    nc_df['log_rr'] = np.log(nc_df['HR_Cox'].astype(float))\n",
    "    nc_df['se_log_rr'] = (np.log(nc_df['HR_CI_High'].astype(float)) - np.log(nc_df['HR_CI_Low'].astype(float))) / 3.92\n",
    "    \n",
    "    # Drop invalid results (infinite or NaN)\n",
    "    nc_df = nc_df.replace([np.inf, -np.inf], np.nan).dropna(subset=['log_rr', 'se_log_rr'])\n",
    "    \n",
    "    # 3. Fit the Null Distribution N(mu, sigma^2)\n",
    "    # We use a weighted moment estimator (inverse variance weighting)\n",
    "    weights = 1.0 / (nc_df['se_log_rr'] ** 2)\n",
    "    \n",
    "    # Mean bias (Systematic Shift)\n",
    "    null_mean = np.average(nc_df['log_rr'], weights=weights)\n",
    "    \n",
    "    # SD bias (Unmeasured Confounding width)\n",
    "    # Variance = weighted average of (x - mean)^2 - average sampling variance\n",
    "    raw_var = np.average((nc_df['log_rr'] - null_mean)**2, weights=weights)\n",
    "    expected_sampling_var = np.average(nc_df['se_log_rr']**2, weights=weights)\n",
    "    \n",
    "    # The systematic variance is the excess variance observed\n",
    "    null_var = max(0, raw_var - expected_sampling_var)\n",
    "    null_sd = np.sqrt(null_var)\n",
    "    \n",
    "    print(f\"  Empirical Null Fitted: Mean Bias = {null_mean:.4f}, SD Bias = {null_sd:.4f}\")\n",
    "    print(f\"  (Interpretation: Mean!=0 implies systematic error; SD>0 implies unmeasured confounding)\")\n",
    "    \n",
    "    # 4. Calibrate All Estimates (Main + NCs)\n",
    "    calibrated_results = results_df.copy()\n",
    "    \n",
    "    # Calculate Log stats for all rows\n",
    "    log_rr = np.log(calibrated_results['HR_Cox'].astype(float))\n",
    "    se_log_rr = (np.log(calibrated_results['HR_CI_High'].astype(float)) - np.log(calibrated_results['HR_CI_Low'].astype(float))) / 3.92\n",
    "    \n",
    "    # Calibrated Z-Score\n",
    "    # We subtract the mean bias and divide by the wider uncertainty (sampling + systematic)\n",
    "    z_cal = (log_rr - null_mean) / np.sqrt(se_log_rr**2 + null_sd**2)\n",
    "    \n",
    "    # Calibrated P-value\n",
    "    calibrated_results['P_Calibrated'] = 2 * (1 - norm.cdf(np.abs(z_cal)))\n",
    "    \n",
    "    # Calibrated CIs (Shifted and Widened)\n",
    "    calibrated_se = np.sqrt(se_log_rr**2 + null_sd**2)\n",
    "    calibrated_results['HR_Calibrated'] = np.exp(log_rr - null_mean)\n",
    "    calibrated_results['HR_Cal_Low'] = np.exp((log_rr - null_mean) - 1.96 * calibrated_se)\n",
    "    calibrated_results['HR_Cal_High'] = np.exp((log_rr - null_mean) + 1.96 * calibrated_se)\n",
    "    \n",
    "    return calibrated_results\n",
    "\n",
    "# Function to plot the calibration (Funnel Plot)\n",
    "def plot_calibration(results_df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot Negative Controls\n",
    "    ncs = results_df[results_df['Outcome'].str.startswith('NC_')]\n",
    "    log_rr_nc = np.log(ncs['HR_Cox'].astype(float))\n",
    "    se_nc = (np.log(ncs['HR_CI_High'].astype(float)) - np.log(ncs['HR_CI_Low'].astype(float))) / 3.92\n",
    "    \n",
    "    plt.scatter(log_rr_nc, 1/se_nc, alpha=0.5, color='gray', label='Negative Controls')\n",
    "    \n",
    "    # Plot Main Outcomes\n",
    "    main = results_df[~results_df['Outcome'].str.startswith('NC_')]\n",
    "    log_rr_main = np.log(main['HR_Cox'].astype(float))\n",
    "    se_main = (np.log(main['HR_CI_High'].astype(float)) - np.log(main['HR_CI_Low'].astype(float))) / 3.92\n",
    "    \n",
    "    plt.scatter(log_rr_main, 1/se_main, color='red', s=100, label='Main Outcomes', zorder=10)\n",
    "    \n",
    "    # Plot Null Line (x=0 is HR=1)\n",
    "    plt.axvline(0, color='black', linestyle='--')\n",
    "    \n",
    "    # Plot Fitted Null Area (Mean +/- SD)\n",
    "    # We just draw the region around 0 to show visual calibration\n",
    "    # (If using the fitted values, draw vertical lines at null_mean)\n",
    "    \n",
    "    plt.xlabel(\"Log Hazard Ratio\")\n",
    "    plt.ylabel(\"Precision (1/SE)\")\n",
    "    plt.title(\"Empirical Calibration Funnel Plot\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b97670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: Clinical Specifics (Labs & Outcomes) [Chunked Version]\n",
    "# =============================================================================\n",
    "print(\"\\n--- CELL 4: Clinical Specifics (Labs & Outcomes) ---\")\n",
    "\n",
    "# --- Helper Function for Chunking ---\n",
    "def get_data_in_chunks(sql_template, all_ids, chunk_size=5000):\n",
    "    \"\"\"\n",
    "    Splits the list of person_ids into smaller chunks to avoid BigQuery\n",
    "    query length limits (1MB).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    ids_list = sorted(list(set(all_ids))) # Ensure unique and list format\n",
    "    \n",
    "    print(f\"  Fetching data for {len(ids_list)} patients in chunks of {chunk_size}...\")\n",
    "    \n",
    "    # Loop through chunks\n",
    "    for i in range(0, len(ids_list), chunk_size):\n",
    "        chunk = ids_list[i : i + chunk_size]\n",
    "        chunk_str = \"(\" + \",\".join(map(str, chunk)) + \")\"\n",
    "        \n",
    "        # Inject the chunk of IDs into the placeholder\n",
    "        query = sql_template.replace(\"PLACEHOLDER_IDS\", chunk_str)\n",
    "        \n",
    "        try:\n",
    "            df_chunk = read_gbq(query, dialect=\"standard\")\n",
    "            results.append(df_chunk)\n",
    "        except Exception as e:\n",
    "            print(f\"    Error in chunk {i}: {e}\")\n",
    "            \n",
    "    if not results:\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    return pd.concat(results, ignore_index=True)\n",
    "\n",
    "# List of all patients in cohort\n",
    "all_cohort_ids = df_cohort.index.tolist()\n",
    "\n",
    "# --- A. Measurements: Strict eGFR vs Creatinine Separation ---\n",
    "\n",
    "# 1. Fetch eGFR\n",
    "# Note: We use PLACEHOLDER_IDS instead of injecting the huge list immediately\n",
    "sql_egfr_template = f\"\"\"\n",
    "SELECT person_id, measurement_date as date, value_as_number\n",
    "FROM `{WORKSPACE_CDR}.measurement`\n",
    "WHERE measurement_concept_id IN ({','.join(map(str, EGFR_CONCEPTS))})\n",
    "AND person_id IN PLACEHOLDER_IDS\n",
    "AND value_as_number > 0 AND value_as_number < 200\n",
    "\"\"\"\n",
    "print(\"Fetching eGFR...\")\n",
    "df_egfr_raw = get_data_in_chunks(sql_egfr_template, all_cohort_ids)\n",
    "df_egfr_raw['date'] = to_naive_utc_day(df_egfr_raw['date'])\n",
    "\n",
    "# 2. Fetch Creatinine\n",
    "sql_creat_template = f\"\"\"\n",
    "SELECT person_id, measurement_date as date, value_as_number\n",
    "FROM `{WORKSPACE_CDR}.measurement`\n",
    "WHERE measurement_concept_id IN ({','.join(map(str, CREATININE_CONCEPTS))})\n",
    "AND person_id IN PLACEHOLDER_IDS\n",
    "AND value_as_number > 0.1 AND value_as_number < 20\n",
    "\"\"\"\n",
    "print(\"Fetching Creatinine...\")\n",
    "df_creat_raw = get_data_in_chunks(sql_creat_template, all_cohort_ids)\n",
    "df_creat_raw['date'] = to_naive_utc_day(df_creat_raw['date'])\n",
    "\n",
    "# Merge to find baseline (Closest prior to index)\n",
    "df_dates = df_cohort[['index_date']].reset_index()\n",
    "\n",
    "# Function to get last value before index\n",
    "def get_baseline_lab(df_lab, df_index, col_name):\n",
    "    if df_lab.empty:\n",
    "        return pd.Series(dtype=float)\n",
    "    merged = df_lab.merge(df_index, on='person_id')\n",
    "    # Strictly prior to index\n",
    "    merged = merged[merged['date'] < merged['index_date']].sort_values('date')\n",
    "    return merged.groupby('person_id')['value_as_number'].last().rename(col_name)\n",
    "\n",
    "df_cohort['baseline_egfr'] = get_baseline_lab(df_egfr_raw, df_dates, 'baseline_egfr')\n",
    "df_cohort['baseline_creat'] = get_baseline_lab(df_creat_raw, df_dates, 'baseline_creat')\n",
    "\n",
    "# Categorical Definitions\n",
    "conditions = [\n",
    "    (df_cohort['baseline_egfr'] < 30),\n",
    "    (df_cohort['baseline_egfr'] >= 30) & (df_cohort['baseline_egfr'] < 45),\n",
    "    (df_cohort['baseline_egfr'] >= 45) & (df_cohort['baseline_egfr'] < 60),\n",
    "    (df_cohort['baseline_egfr'] >= 60)\n",
    "]\n",
    "df_cohort['egfr_cat'] = np.select(conditions, [0, 1, 2, 3], default=4) # 4 is Missing\n",
    "\n",
    "# --- B. Outcomes & Pre-Existing Conditions ---\n",
    "all_outcome_concepts = OUTCOME_CONCEPTS.union(THYROTOXICOSIS_IDS).union(ALL_NEGATIVE_CONTROL_IDS)\n",
    "\n",
    "# Note: We construct the UNION ALL inside the template, but both parts need PLACEHOLDER_IDS\n",
    "sql_outcomes_template = f\"\"\"\n",
    "SELECT person_id, condition_start_date as event_date, condition_concept_id\n",
    "FROM `{WORKSPACE_CDR}.condition_occurrence`\n",
    "WHERE condition_concept_id IN ({','.join(map(str, all_outcome_concepts))})\n",
    "AND person_id IN PLACEHOLDER_IDS\n",
    "UNION ALL\n",
    "SELECT person_id, death_date as event_date, 0 as condition_concept_id\n",
    "FROM `{WORKSPACE_CDR}.death`\n",
    "WHERE person_id IN PLACEHOLDER_IDS\n",
    "\"\"\"\n",
    "print(\"Fetching Outcomes & Events...\")\n",
    "df_events = get_data_in_chunks(sql_outcomes_template, all_cohort_ids)\n",
    "df_events['event_date'] = to_naive_utc_day(df_events['event_date'])\n",
    "df_events = df_events.merge(df_dates, on='person_id')\n",
    "\n",
    "# 1. Pre-existing Thyrotoxicosis\n",
    "pre_thyro = df_events[\n",
    "    (df_events['condition_concept_id'].isin(THYROTOXICOSIS_IDS)) & \n",
    "    (df_events['event_date'] < df_events['index_date'])\n",
    "]\n",
    "df_cohort['hx_thyrotoxicosis'] = 0\n",
    "df_cohort.loc[df_cohort.index.isin(pre_thyro['person_id']), 'hx_thyrotoxicosis'] = 1\n",
    "\n",
    "# 2. Standardized Outcome Dates\n",
    "# Death\n",
    "df_death = df_events[df_events['condition_concept_id'] == 0]\n",
    "df_cohort['date_DEATH'] = df_death.groupby('person_id')['event_date'].min()\n",
    "\n",
    "# Map Specific Outcomes\n",
    "for outcome, (concepts, window) in ANALYSIS_OUTCOMES.items():\n",
    "    if outcome in ['MORTALITY_30', 'MAE_30']: continue \n",
    "    \n",
    "    events = df_events[\n",
    "        (df_events['condition_concept_id'].isin(concepts)) & \n",
    "        (df_events['event_date'] >= df_events['index_date'])\n",
    "    ]\n",
    "    df_cohort[f'date_{outcome}'] = events.groupby('person_id')['event_date'].min()\n",
    "\n",
    "# Composite MAE_30\n",
    "mae_cols = ['date_AKI_30', 'date_NEW_DIALYSIS_90', 'date_DEATH']\n",
    "mae_valid = [c for c in mae_cols if c in df_cohort.columns]\n",
    "if mae_valid:\n",
    "    df_cohort['date_MAE_30'] = df_cohort[mae_valid].min(axis=1)\n",
    "\n",
    "# Negative Controls\n",
    "for name, concepts in NEGATIVE_CONTROLS.items():\n",
    "    events = df_events[\n",
    "        (df_events['condition_concept_id'].isin(concepts)) & \n",
    "        (df_events['event_date'] >= df_events['index_date'])\n",
    "    ]\n",
    "    df_cohort[f'date_{name}'] = events.groupby('person_id')['event_date'].min()\n",
    "\n",
    "print(\"Clinical Specifics Attached (Chunked).\")\n",
    "clean_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55b8d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: High-Dimensional Feature Extraction (Robust High-RAM Version)\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from pandas_gbq import read_gbq\n",
    "import gc\n",
    "\n",
    "print(\"\\n--- CELL 5: High-Dimensional Feature Extraction ---\")\n",
    "\n",
    "# 1. Setup & Helper Functions\n",
    "# ---------------------------------------------------------\n",
    "# Define Exclusions (Exposure itself)\n",
    "exclusions = ALL_IMAGING \n",
    "exclude_str = f\"({','.join(map(str, exclusions))})\"\n",
    "\n",
    "# Get list of ALL patient IDs from the cohort dataframe\n",
    "# This fixes the NameError\n",
    "all_cohort_ids = df_cohort.index.tolist()\n",
    "\n",
    "def get_data_in_chunks(sql_template, all_ids, chunk_size=4000):\n",
    "    \"\"\"Downloads data in chunks to satisfy BigQuery 1MB query limit.\"\"\"\n",
    "    results = []\n",
    "    ids_list = sorted(list(set(all_ids)))\n",
    "    print(f\"  Downloading data for {len(ids_list)} patients (Chunks of {chunk_size})...\")\n",
    "    \n",
    "    for i in range(0, len(ids_list), chunk_size):\n",
    "        chunk = ids_list[i : i + chunk_size]\n",
    "        # Robust string formatting for the IN clause\n",
    "        chunk_str = \"(\" + \",\".join(map(str, chunk)) + \")\"\n",
    "        query = sql_template.replace(\"PLACEHOLDER_IDS\", chunk_str)\n",
    "        try:\n",
    "            df_chunk = read_gbq(query, dialect=\"standard\")\n",
    "            results.append(df_chunk)\n",
    "            print(f\"    Chunk {i//chunk_size + 1} downloaded ({len(df_chunk)} rows)\")\n",
    "        except Exception as e:\n",
    "            print(f\"    Error in chunk {i}: {e}\")\n",
    "            \n",
    "    if not results: return pd.DataFrame()\n",
    "    return pd.concat(results, ignore_index=True)\n",
    "\n",
    "# 2. SQL Construction (Template)\n",
    "# ---------------------------------------------------------\n",
    "# We use PLACEHOLDER_IDS instead of injecting the huge list\n",
    "sql_features_template = f\"\"\"\n",
    "WITH Cohort AS (\n",
    "    SELECT \n",
    "        p.person_id, \n",
    "        CAST(p.procedure_datetime AS DATE) as index_date\n",
    "    FROM `{WORKSPACE_CDR}.procedure_occurrence` p\n",
    "    WHERE p.person_id IN PLACEHOLDER_IDS\n",
    "    AND p.procedure_concept_id IN ({','.join(map(str, ALL_IMAGING))})\n",
    ")\n",
    "SELECT \n",
    "    c.person_id, \n",
    "    CAST(c.condition_concept_id AS STRING) as feature_id, \n",
    "    'COND' as domain\n",
    "FROM `{WORKSPACE_CDR}.condition_occurrence` c\n",
    "JOIN Cohort i ON c.person_id = i.person_id\n",
    "WHERE c.condition_start_date < i.index_date \n",
    "  AND c.condition_concept_id NOT IN {exclude_str}\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    d.person_id, \n",
    "    CAST(d.drug_concept_id AS STRING) as feature_id, \n",
    "    'DRUG' as domain\n",
    "FROM `{WORKSPACE_CDR}.drug_exposure` d\n",
    "JOIN Cohort i ON d.person_id = i.person_id\n",
    "WHERE d.drug_exposure_start_date < i.index_date\n",
    "  AND d.drug_concept_id NOT IN {exclude_str}\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    p.person_id, \n",
    "    CAST(p.procedure_concept_id AS STRING) as feature_id, \n",
    "    'PROC' as domain\n",
    "FROM `{WORKSPACE_CDR}.procedure_occurrence` p\n",
    "JOIN Cohort i ON p.person_id = i.person_id\n",
    "WHERE p.procedure_date < i.index_date\n",
    "  AND p.procedure_concept_id NOT IN {exclude_str}\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    m.person_id, \n",
    "    CAST(m.measurement_concept_id AS STRING) as feature_id, \n",
    "    'MEAS' as domain\n",
    "FROM `{WORKSPACE_CDR}.measurement` m\n",
    "JOIN Cohort i ON m.person_id = i.person_id\n",
    "WHERE m.measurement_date < i.index_date\n",
    "  AND m.measurement_concept_id NOT IN {exclude_str}\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    o.person_id, \n",
    "    CONCAT(CAST(o.observation_concept_id AS STRING), '_', CAST(COALESCE(o.value_as_concept_id, 0) AS STRING)) as feature_id, \n",
    "    'OBS' as domain\n",
    "FROM `{WORKSPACE_CDR}.observation` o\n",
    "JOIN Cohort i ON o.person_id = i.person_id\n",
    "WHERE o.observation_date < i.index_date\n",
    "  AND o.observation_concept_id NOT IN {exclude_str}\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    dv.person_id, \n",
    "    CAST(dv.device_concept_id AS STRING) as feature_id, \n",
    "    'DEV' as domain\n",
    "FROM `{WORKSPACE_CDR}.device_exposure` dv\n",
    "JOIN Cohort i ON dv.person_id = i.person_id\n",
    "WHERE dv.device_exposure_start_date < i.index_date\n",
    "  AND dv.device_concept_id NOT IN {exclude_str}\n",
    "\"\"\"\n",
    "\n",
    "# 3. Execution (Chunked Download + High-Speed Processing)\n",
    "# ---------------------------------------------------------\n",
    "print(\"Starting High-RAM Feature Extraction...\")\n",
    "\n",
    "# A. Download\n",
    "df_features = get_data_in_chunks(sql_features_template, all_cohort_ids)\n",
    "\n",
    "# B. Process (Vectorized)\n",
    "if not df_features.empty:\n",
    "    print(f\"Total raw features rows: {len(df_features):,}\")\n",
    "    \n",
    "    # Create PID mapping if missing\n",
    "    if 'pid_to_idx' not in locals():\n",
    "        pid_to_idx = {pid: i for i, pid in enumerate(df_cohort.index)}\n",
    "    \n",
    "    # Filter to cohort (safety)\n",
    "    df_features = df_features[df_features['person_id'].isin(pid_to_idx)].copy()\n",
    "    \n",
    "    # Vectorized string concat (Fast)\n",
    "    df_features['feature_name'] = df_features['domain'] + '_' + df_features['feature_id']\n",
    "    \n",
    "    # Count\n",
    "    feature_counts = df_features['feature_name'].value_counts()\n",
    "    \n",
    "    # Filter Prevalence >= 50\n",
    "    valid_feats_set = set(feature_counts[feature_counts >= 50].index)\n",
    "    feat_to_idx = {feat: i for i, feat in enumerate(sorted(list(valid_feats_set)))}\n",
    "    \n",
    "    print(f\"Unique Features: {len(feature_counts)}. Retained (>=50): {len(valid_feats_set)}\")\n",
    "    \n",
    "    # Final Filter\n",
    "    df_features_valid = df_features[df_features['feature_name'].isin(valid_feats_set)]\n",
    "    \n",
    "    # C. Build Matrix\n",
    "    print(\"Building Sparse Matrix...\")\n",
    "    row_indices = df_features_valid['person_id'].map(pid_to_idx).values\n",
    "    col_indices = df_features_valid['feature_name'].map(feat_to_idx).values\n",
    "    values = np.ones(len(row_indices))\n",
    "    \n",
    "    X_sparse = sp.coo_matrix(\n",
    "        (values, (row_indices, col_indices)),\n",
    "        shape=(len(df_cohort), len(valid_feats_set))\n",
    "    ).tocsr()\n",
    "    \n",
    "    # Binarize\n",
    "    X_sparse.data = np.ones_like(X_sparse.data)\n",
    "    \n",
    "    print(f\"Final Sparse Matrix Shape: {X_sparse.shape}\")\n",
    "    \n",
    "    # Clean Memory\n",
    "    del df_features, df_features_valid, row_indices, col_indices\n",
    "    gc.collect()\n",
    "    \n",
    "else:\n",
    "    print(\"CRITICAL WARNING: No feature history found for this cohort.\")\n",
    "    X_sparse = sp.csr_matrix((len(df_cohort), 0))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0216476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil\n",
    "\n",
    "def print_disk_usage(tag=\"\"):\n",
    "    \"\"\"Print total, used, and free disk space for the main volume.\"\"\"\n",
    "    du = psutil.disk_usage('/')\n",
    "    total_gb = du.total / (1024**3)\n",
    "    used_gb  = du.used  / (1024**3)\n",
    "    free_gb  = du.free  / (1024**3)\n",
    "    pct = du.percent\n",
    "    print(f\"[DISK] {tag}\")\n",
    "    print(f\"       Total: {total_gb:6.1f} GB\")\n",
    "    print(f\"       Used : {used_gb:6.1f} GB ({pct:4.1f}%)\")\n",
    "    print(f\"       Free : {free_gb:6.1f} GB\")\n",
    "    print(\"\")\n",
    "\n",
    "def list_dir_with_sizes(path=\".\", max_files=50):\n",
    "    \"\"\"List files in a directory with sizes in MB, capped at max_files.\"\"\"\n",
    "    print(f\"[FILES] Listing '{os.path.abspath(path)}' (showing up to {max_files} entries):\")\n",
    "    files = os.listdir(path)\n",
    "    for fname in files[:max_files]:\n",
    "        fpath = os.path.join(path, fname)\n",
    "        if os.path.isfile(fpath):\n",
    "            size_mb = os.path.getsize(fpath) / (1024**2)\n",
    "            print(f\"   {fname:40s} {size_mb:10.2f} MB\")\n",
    "        else:\n",
    "            print(f\"   {fname:40s} <DIR>\")\n",
    "    if len(files) > max_files:\n",
    "        print(f\"   ... ({len(files)-max_files} more files)\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd039c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil\n",
    "\n",
    "def print_disk_usage(tag=\"\"):\n",
    "    \"\"\"Print total, used, and free disk space for the main volume.\"\"\"\n",
    "    du = psutil.disk_usage('/')\n",
    "    total_gb = du.total / (1024**3)\n",
    "    used_gb  = du.used  / (1024**3)\n",
    "    free_gb  = du.free  / (1024**3)\n",
    "    pct = du.percent\n",
    "    print(f\"[DISK] {tag}\")\n",
    "    print(f\"       Total: {total_gb:6.1f} GB\")\n",
    "    print(f\"       Used : {used_gb:6.1f} GB ({pct:4.1f}%)\")\n",
    "    print(f\"       Free : {free_gb:6.1f} GB\")\n",
    "    print(\"\")\n",
    "\n",
    "def list_dir_with_sizes(path=\".\", max_files=50):\n",
    "    \"\"\"List files in a directory with sizes in MB, capped at max_files.\"\"\"\n",
    "    print(f\"[FILES] Listing '{os.path.abspath(path)}' (showing up to {max_files} entries):\")\n",
    "    files = os.listdir(path)\n",
    "    for fname in files[:max_files]:\n",
    "        fpath = os.path.join(path, fname)\n",
    "        if os.path.isfile(fpath):\n",
    "            size_mb = os.path.getsize(fpath) / (1024**2)\n",
    "            print(f\"   {fname:40s} {size_mb:10.2f} MB\")\n",
    "        else:\n",
    "            print(f\"   {fname:40s} <DIR>\")\n",
    "    if len(files) > max_files:\n",
    "        print(f\"   ... ({len(files)-max_files} more files)\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b58950",
   "metadata": {},
   "source": [
    "MIDPOINT!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f61b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import scipy.sparse as sp\n",
    "\n",
    "\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "def print_disk_usage(tag=\"\"):\n",
    "    \"\"\"Print total, used, and free disk space for the main volume.\"\"\"\n",
    "    du = psutil.disk_usage('/')\n",
    "    total_gb = du.total / (1024**3)\n",
    "    used_gb  = du.used  / (1024**3)\n",
    "    free_gb  = du.free  / (1024**3)\n",
    "    pct = du.percent\n",
    "    print(f\"[DISK] {tag}\")\n",
    "    print(f\"       Total: {total_gb:6.1f} GB\")\n",
    "    print(f\"       Used : {used_gb:6.1f} GB ({pct:4.1f}%)\")\n",
    "    print(f\"       Free : {free_gb:6.1f} GB\")\n",
    "    print(\"\")\n",
    "\n",
    "def list_dir_with_sizes(path=\".\", max_files=50):\n",
    "    \"\"\"List files in a directory with sizes in MB, capped at max_files.\"\"\"\n",
    "    print(f\"[FILES] Listing '{os.path.abspath(path)}' (showing up to {max_files} entries):\")\n",
    "    files = os.listdir(path)\n",
    "    for fname in files[:max_files]:\n",
    "        fpath = os.path.join(path, fname)\n",
    "        if os.path.isfile(fpath):\n",
    "            size_mb = os.path.getsize(fpath) / (1024**2)\n",
    "            print(f\"   {fname:40s} {size_mb:10.2f} MB\")\n",
    "        else:\n",
    "            print(f\"   {fname:40s} <DIR>\")\n",
    "    if len(files) > max_files:\n",
    "        print(f\"   ... ({len(files)-max_files} more files)\")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "print(\"=== RELOADING CHECKPOINT ===\")\n",
    "print_disk_usage(\"Before loading\")\n",
    "list_dir_with_sizes(\".\")\n",
    "\n",
    "\n",
    "df_cohort   = pd.read_parquet(\"df_cohort.parquet\")\n",
    "X_sparse    = sp.load_npz(\"X_sparse.npz\")\n",
    "pid_to_idx  = joblib.load(\"pid_to_idx.joblib\")\n",
    "feat_to_idx = joblib.load(\"feat_to_idx.joblib\")\n",
    "\n",
    "print(\"Reload complete.\")\n",
    "\n",
    "print_disk_usage(\"After loading\")\n",
    "list_dir_with_sizes(\".\")\n",
    "\n",
    "print(\"df_cohort shape:\", df_cohort.shape)\n",
    "print(\"X_sparse shape :\", X_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b73f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"=== Sanity check: reload from disk into new variables ===\")\n",
    "print(\"Files on disk:\", os.listdir(\".\"))\n",
    "\n",
    "# 1. Reload\n",
    "df_cohort_disk = pd.read_parquet(\"df_cohort.parquet\")\n",
    "X_sparse_disk  = sp.load_npz(\"X_sparse.npz\")\n",
    "pid_to_idx_disk  = joblib.load(\"pid_to_idx.joblib\")\n",
    "feat_to_idx_disk = joblib.load(\"feat_to_idx.joblib\")\n",
    "\n",
    "print(\"df_cohort RAM shape :\", df_cohort.shape)\n",
    "print(\"df_cohort DISK shape:\", df_cohort_disk.shape)\n",
    "\n",
    "print(\"X_sparse RAM shape  :\", X_sparse.shape)\n",
    "print(\"X_sparse DISK shape :\", X_sparse_disk.shape)\n",
    "\n",
    "print(\"pid_to_idx sizes    :\", len(pid_to_idx), len(pid_to_idx_disk))\n",
    "print(\"feat_to_idx sizes   :\", len(feat_to_idx), len(feat_to_idx_disk))\n",
    "\n",
    "# 2. Quick content checks (cheap)\n",
    "print(\"df_cohort columns equal?:\", list(df_cohort.columns) == list(df_cohort_disk.columns))\n",
    "print(\"First 5 rows equal?     :\", df_cohort.head().reset_index(drop=True).equals(\n",
    "    df_cohort_disk.head().reset_index(drop=True)\n",
    "))\n",
    "\n",
    "# Sparse: check a few random rows instead of full matrix diff\n",
    "rng = np.random.default_rng(42)\n",
    "idx_sample = rng.choice(X_sparse.shape[0], size=5, replace=False)\n",
    "\n",
    "ok_sparse = True\n",
    "for i in idx_sample:\n",
    "    row_ram  = X_sparse[i].toarray()\n",
    "    row_disk = X_sparse_disk[i].toarray()\n",
    "    if not np.array_equal(row_ram, row_disk):\n",
    "        ok_sparse = False\n",
    "        print(f\"Row {i} mismatch\")\n",
    "        break\n",
    "\n",
    "print(\"Sampled sparse rows equal?:\", ok_sparse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: Feature Engineering & Alignment (Optimized + TQDM)\n",
    "# =============================================================================\n",
    "print(\"\\n--- CELL 6: Feature Engineering & Alignment ---\")\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Setup Progress Bar\n",
    "pbar = tqdm(total=6, desc=\"Initializing\")\n",
    "\n",
    "# 1. Align Dataframe to Sparse Matrix\n",
    "pbar.set_description(\"Aligning Dataframes\")\n",
    "if 'pid_to_idx' not in locals():\n",
    "    raise ValueError(\"Missing pid_to_idx! Please run Cell 5.5.\")\n",
    "\n",
    "sorted_pids = sorted(pid_to_idx, key=pid_to_idx.get)\n",
    "df_cohort_aligned = df_cohort.loc[sorted_pids].copy()\n",
    "\n",
    "# Safety Check\n",
    "assert len(df_cohort_aligned) == X_sparse.shape[0], \"Row count mismatch between Dense and Sparse!\"\n",
    "assert df_cohort_aligned.index[0] == sorted_pids[0], \"Index alignment error!\"\n",
    "\n",
    "print(f\"Aligned Cohort N={len(df_cohort_aligned)}\")\n",
    "pbar.update(1)\n",
    "\n",
    "# 2. Feature Engineering: Dense Covariates\n",
    "\n",
    "# A. Site Rate Smoothing\n",
    "pbar.set_description(\"Smoothing Site Rates\")\n",
    "if 'zip_code' in df_cohort_aligned.columns:\n",
    "    # Use float32 to save RAM if dataset is massive, otherwise default float is fine\n",
    "    site_counts = df_cohort_aligned.groupby('zip_code')['contrast_received'].agg(['mean', 'count'])\n",
    "    global_mean = df_cohort_aligned['contrast_received'].mean()\n",
    "    C_smooth = 10 \n",
    "    site_counts['smoothed_rate'] = (site_counts['mean'] * site_counts['count'] + global_mean * C_smooth) / (site_counts['count'] + C_smooth)\n",
    "    df_cohort_aligned['site_contrast_rate'] = df_cohort_aligned['zip_code'].map(site_counts['smoothed_rate']).fillna(global_mean)\n",
    "else:\n",
    "    df_cohort_aligned['site_contrast_rate'] = df_cohort_aligned['contrast_received'].mean()\n",
    "pbar.update(1)\n",
    "\n",
    "# B. Imputation & Scaling\n",
    "pbar.set_description(\"Imputing & Scaling\")\n",
    "# Handle Imputation\n",
    "for col in ['baseline_egfr', 'baseline_creat']:\n",
    "    if col in df_cohort_aligned.columns:\n",
    "        df_cohort_aligned[f'{col}_missing'] = df_cohort_aligned[col].isna().astype(float) # Direct to float\n",
    "        df_cohort_aligned[f'{col}_imputed'] = df_cohort_aligned[col].fillna(df_cohort_aligned[col].median())\n",
    "    else:\n",
    "        df_cohort_aligned[f'{col}_missing'] = 1.0\n",
    "        df_cohort_aligned[f'{col}_imputed'] = 0.0\n",
    "\n",
    "# Handle Scaling\n",
    "dense_cols_to_scale = ['age', 'site_contrast_rate', 'baseline_egfr_imputed', 'baseline_creat_imputed']\n",
    "dense_cols_to_scale = [c for c in dense_cols_to_scale if c in df_cohort_aligned.columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Output directly as float\n",
    "X_dense_scaled = scaler.fit_transform(df_cohort_aligned[dense_cols_to_scale].fillna(0))\n",
    "pbar.update(1)\n",
    "\n",
    "# C. Categorical Dummies \n",
    "# OPTIMIZATION: dtype=float here prevents a massive copy/cast later\n",
    "pbar.set_description(\"Generating Dummies\")\n",
    "\n",
    "if 'egfr_cat' in df_cohort_aligned.columns:\n",
    "    egfr_dummies = pd.get_dummies(df_cohort_aligned['egfr_cat'], prefix='egfr_cat', dtype=float)\n",
    "else:\n",
    "    egfr_dummies = pd.DataFrame()\n",
    "\n",
    "df_cohort_aligned['age_decile'] = pd.qcut(df_cohort_aligned['age'], q=10, labels=False, duplicates='drop')\n",
    "age_dummies = pd.get_dummies(df_cohort_aligned['age_decile'], prefix='age_decile', dtype=float)\n",
    "\n",
    "gender_dummies = pd.get_dummies(df_cohort_aligned['gender_concept_id'], prefix='gender', dtype=float)\n",
    "\n",
    "# Direct float conversion\n",
    "thyro_dummy = df_cohort_aligned[['hx_thyrotoxicosis']].astype(float)\n",
    "missing_flags = df_cohort_aligned[[c for c in df_cohort_aligned.columns if c.endswith('_missing')]].astype(float)\n",
    "pbar.update(1)\n",
    "\n",
    "# 3. Combine All Dense Features\n",
    "pbar.set_description(\"Concatenating Dense Matrix\")\n",
    "X_dense_list = [\n",
    "    pd.DataFrame(X_dense_scaled, index=df_cohort_aligned.index, columns=dense_cols_to_scale),\n",
    "    egfr_dummies,\n",
    "    age_dummies,\n",
    "    gender_dummies,\n",
    "    thyro_dummy,\n",
    "    missing_flags\n",
    "]\n",
    "\n",
    "# OPTIMIZATION: No .astype(float) needed here anymore, saving one full memory write\n",
    "df_dense_final = pd.concat(X_dense_list, axis=1)\n",
    "X_dense = sp.csr_matrix(df_dense_final.values)\n",
    "pbar.update(1)\n",
    "\n",
    "# 4. Final Stack (Dense + Sparse)\n",
    "pbar.set_description(\"Final Stack (HStack)\")\n",
    "X_all = sp.hstack([X_dense, X_sparse], format='csr')\n",
    "pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "clean_mem()\n",
    "print(f\"Final Input Matrix Shape: {X_all.shape}\")\n",
    "print(f\"Dense Features included ({df_dense_final.shape[1]}): {list(df_dense_final.columns[:10])} ...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773109c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 7A: Hyperparameter Tuning on 10k Subsample ---\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "T = df_cohort_aligned['contrast_received'].values\n",
    "N = len(T)\n",
    "\n",
    "print(f\"Full cohort: N={N}, P={X_all.shape[1]}\")\n",
    "\n",
    "# --- 1. Choose a ~10k stratified subsample ---\n",
    "target_n = 10_000\n",
    "if N <= target_n:\n",
    "    print(\"N <= 10k, using full cohort for tuning.\")\n",
    "    idx_sub = np.arange(N)\n",
    "else:\n",
    "    frac = target_n / N\n",
    "    sss = StratifiedShuffleSplit(\n",
    "        n_splits=1,\n",
    "        test_size=frac,\n",
    "        random_state=42\n",
    "    )\n",
    "    _, idx_sub = next(sss.split(X_all, T))\n",
    "    print(f\"Using subsample of size {len(idx_sub)} for tuning.\")\n",
    "\n",
    "X_sub = X_all[idx_sub]\n",
    "T_sub = T[idx_sub]\n",
    "\n",
    "# --- 2. Define base logistic model ---\n",
    "# saga supports L1/L2 with large, possibly sparse, high-dim data.\n",
    "base_logit = LogisticRegression(\n",
    "    penalty='l1',              # we'll start with L1; could swap to 'l2'\n",
    "    solver='saga',             # good for large P, supports l1\n",
    "    max_iter=3000,\n",
    "    class_weight='balanced',   # very standard for PS in imbalanced settings\n",
    "    n_jobs=-1,                 # use all visible cores inside each fit\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- 3. Grid over C (log-scale) ---\n",
    "param_grid = {\n",
    "    \"C\": np.logspace(-3, 0, 6)   # 0.001, 0.0032, 0.01, 0.032, 0.1, 1.0\n",
    "}\n",
    "\n",
    "print(\"Tuning C on subsample using 3-fold CV (scoring=roc_auc)...\")\n",
    "gs = GridSearchCV(\n",
    "    estimator=base_logit,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "gs.fit(X_sub, T_sub)\n",
    "\n",
    "best_C = gs.best_params_[\"C\"]\n",
    "best_score = gs.best_score_\n",
    "\n",
    "print(f\"Best C: {best_C:.4g} (mean CV AUC: {best_score:.4f})\")\n",
    "\n",
    "# We'll reuse this C downstream\n",
    "C_best = float(best_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d1fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 7B: Cross-Fitted PS (Parallel Over Folds, Tunable Core Use) ---\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "T = df_cohort_aligned['contrast_received'].values\n",
    "N, P = X_all.shape\n",
    "print(f\"Training cross-fitted PS on full cohort (N={N}, P={P}, C={C_best})\")\n",
    "\n",
    "outer_k = 5\n",
    "cv_outer = StratifiedKFold(\n",
    "    n_splits=outer_k,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ---- CORE / THREAD SETTINGS ----\n",
    "threads_per_fold = 6  \n",
    "n_folds_workers = min(outer_k, 32 // threads_per_fold or 1)\n",
    "\n",
    "print(f\"Using up to {n_folds_workers} folds in parallel, \"\n",
    "      f\"{threads_per_fold} threads per fold (target ~{n_folds_workers * threads_per_fold} cores)\")\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(threads_per_fold)\n",
    "os.environ[\"MKL_NUM_THREADS\"] = str(threads_per_fold)\n",
    "\n",
    "def fit_one_fold(fold_id, train_idx, test_idx, X, T, C_best):\n",
    "    \"\"\"Train L1-logistic on one fold and return PS for its test indices.\"\"\"\n",
    "    t0 = time.time()\n",
    "    print(f\"[Fold {fold_id}] start: train={len(train_idx)}, test={len(test_idx)}\")\n",
    "\n",
    "    logit = LogisticRegression(\n",
    "        penalty='l1',\n",
    "        solver='saga',\n",
    "        C=C_best,\n",
    "        max_iter=1500,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=threads_per_fold,   # <-- threads per fold\n",
    "        random_state=42 + fold_id\n",
    "    )\n",
    "    logit.fit(X[train_idx], T[train_idx])\n",
    "    ps_fold = logit.predict_proba(X[test_idx])[:, 1]\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(f\"[Fold {fold_id}] done in {(t1 - t0)/60:.2f} min\")\n",
    "\n",
    "    return fold_id, test_idx, ps_fold\n",
    "\n",
    "# Prepare fold tasks\n",
    "fold_tasks = [\n",
    "    (fold_id, train_idx, test_idx)\n",
    "    for fold_id, (train_idx, test_idx)\n",
    "    in enumerate(cv_outer.split(X_all, T), start=1)\n",
    "]\n",
    "\n",
    "# Run folds in parallel\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "print(f\"Running {outer_k} folds with joblib (n_jobs={n_folds_workers})...\")\n",
    "results = Parallel(\n",
    "    n_jobs=n_folds_workers,\n",
    "    verbose=10,\n",
    "    backend=\"loky\"\n",
    ")(\n",
    "    delayed(fit_one_fold)(fold_id, train_idx, test_idx, X_all, T, C_best)\n",
    "    for (fold_id, train_idx, test_idx) in fold_tasks\n",
    ")\n",
    "\n",
    "# Merge PS\n",
    "ps = np.zeros(N, dtype=float)\n",
    "for fold_id, test_idx, ps_fold in results:\n",
    "    ps[test_idx] = ps_fold\n",
    "\n",
    "df_cohort_aligned['ps'] = ps\n",
    "\n",
    "print(\"Fitting final global model on full data for interpretation...\")\n",
    "lsps_model = LogisticRegression(\n",
    "    penalty='l1',\n",
    "    solver='saga',\n",
    "    C=C_best,\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1,\n",
    "    random_state=999\n",
    ")\n",
    "lsps_model.fit(X_all, T)\n",
    "\n",
    "print(\"Cross-fitting complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8cc71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "print(\"\\n=== CHECKPOINT: Saving Model & Cross-Fitted Scores ===\")\n",
    "\n",
    "# 1. Save the Global Model (for coefficients/interpretation)\n",
    "joblib.dump(lsps_model, 'lsps_model_global.joblib')\n",
    "print(\"Saved Global Logistic Model (lsps_model_global.joblib)\")\n",
    "\n",
    "# 2. Save the Dataframe WITH the 'ps' column\n",
    "# We need to save the aligned version because it matches the X matrix rows\n",
    "# and contains the critical 'ps' and 'iptw' columns.\n",
    "df_cohort_aligned.to_parquet('df_cohort_with_ps.parquet')\n",
    "print(\"Saved Cohort with PS scores (df_cohort_with_ps.parquet)\")\n",
    "\n",
    "# 3. Save the C_best parameter (just in case)\n",
    "joblib.dump(C_best, 'C_best_param.joblib')\n",
    "\n",
    "print(\"Checkpoint Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e22e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 7_LOAD: Reload Model & Scores (Skip Training)\n",
    "# =============================================================================\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- RELOADING PS MODEL & SCORES ---\")\n",
    "\n",
    "# 1. Load the Dataframe with PS\n",
    "# This restores the Cross-Fitted scores (crucial for valid inference)\n",
    "df_cohort_aligned = pd.read_parquet('df_cohort_with_ps.parquet')\n",
    "print(f\"Restored dataframe with PS. Shape: {df_cohort_aligned.shape}\")\n",
    "\n",
    "# 2. Load the Global Model\n",
    "# This restores the coefficients for interpretation\n",
    "lsps_model = joblib.load('lsps_model_global.joblib')\n",
    "print(\"Restored Global Model.\")\n",
    "\n",
    "# 3. Load Hyperparams\n",
    "try:\n",
    "    C_best = joblib.load('C_best_param.joblib')\n",
    "    print(f\"Restored C_best: {C_best}\")\n",
    "except:\n",
    "    print(\"C_best not found, setting default.\")\n",
    "    C_best = 0.1 # Default fallback\n",
    "\n",
    "# 4. Consistency Check\n",
    "# Ensure the dataframe aligns with the X_all matrix you just generated in Cell 6\n",
    "# (This assumes you ran Cells 1-6 first)\n",
    "if 'X_all' in locals():\n",
    "    assert len(df_cohort_aligned) == X_all.shape[0], \"Row count mismatch! Did you re-run Cell 6?\"\n",
    "    \n",
    "    # Re-define T for downstream cells\n",
    "    T = df_cohort_aligned['contrast_received'].values\n",
    "    print(\"Consistency check passed. Ready for Diagnostics (Cell 7C).\")\n",
    "else:\n",
    "    print(\"WARNING: X_all variable not found in RAM. Please run Cell 6 (Feature Engineering) before proceeding to Love Plots.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 7C: Diagnostics, Trimming, Weights, ESS ---\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# PS diagnostics\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.kdeplot(\n",
    "    df_cohort_aligned.loc[df_cohort_aligned['contrast_received'] == 0, 'ps'],\n",
    "    fill=True, alpha=0.3, label='Control'\n",
    ")\n",
    "sns.kdeplot(\n",
    "    df_cohort_aligned.loc[df_cohort_aligned['contrast_received'] == 1, 'ps'],\n",
    "    fill=True, alpha=0.3, label='Treated'\n",
    ")\n",
    "plt.title(\"Propensity Score Overlap (Cross-Fitted, saga/l1)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Trimming\n",
    "ps = df_cohort_aligned['ps'].values\n",
    "mask_keep = (ps > 0.025) & (ps < 0.975)\n",
    "df_final = df_cohort_aligned[mask_keep].copy()\n",
    "X_final = X_all[mask_keep]\n",
    "T_final = T[mask_keep]\n",
    "ps_final = ps[mask_keep]\n",
    "\n",
    "print(f\"Original N: {N}\")\n",
    "print(f\"Trimmed  N: {len(df_final)} (Removed {N - len(df_final)})\")\n",
    "\n",
    "# IPW weights (stabilized)\n",
    "p_t = T_final.mean()\n",
    "weights = np.where(\n",
    "    T_final == 1,\n",
    "    p_t / ps_final,\n",
    "    (1 - p_t) / (1 - ps_final)\n",
    ")\n",
    "df_final['iptw'] = weights\n",
    "\n",
    "# Effective sample size\n",
    "ess = calculate_ess(weights)\n",
    "print(f\"Effective Sample Size (ESS): {ess:.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d0be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DIAGNOSTIC ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Get Feature Names\n",
    "# Dense names from Cell 6\n",
    "dense_names = list(df_dense_final.columns)\n",
    "# Sparse names from the mapping in Cell 5.5\n",
    "# We need to invert the feat_to_idx dictionary\n",
    "idx_to_feat = {v: k for k, v in feat_to_idx.items()}\n",
    "sparse_names = [idx_to_feat[i] for i in range(len(feat_to_idx))]\n",
    "all_feature_names = dense_names + sparse_names\n",
    "\n",
    "# 2. Get Coefficients from the Lasso Model\n",
    "# The model is 'lsps_cv' from Cell 7\n",
    "coefs = lsps_model.coef_[0]\n",
    "\n",
    "# 3. Sort and Display\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Coefficient': coefs,\n",
    "    'Abs_Coef': np.abs(coefs)\n",
    "})\n",
    "\n",
    "print(\"\\n--- TOP 30 PREDICTORS OF RECEIVING CONTRAST ---\")\n",
    "print(coef_df.sort_values('Coefficient', ascending=False).head(30)[['Feature', 'Coefficient']])\n",
    "\n",
    "print(\"\\n--- TOP 30 PREDICTORS OF WITHHOLDING CONTRAST ---\")\n",
    "print(coef_df.sort_values('Coefficient', ascending=True).head(30)[['Feature', 'Coefficient']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a9f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 7.5: POST-WEIGHTING EQUIPOISE & OVERLAP DIAGNOSTICS ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def calculate_overlap_coefficient(data0, data1, weights0, weights1, bins=100):\n",
    "    \"\"\"Calculates the overlapping area of two weighted density distributions (0 to 1).\"\"\"\n",
    "    # Create common bin edges\n",
    "    min_val = min(data0.min(), data1.min())\n",
    "    max_val = max(data0.max(), data1.max())\n",
    "    bins_edges = np.linspace(min_val, max_val, bins)\n",
    "    \n",
    "    # Calculate weighted histograms\n",
    "    hist0, _ = np.histogram(data0, bins=bins_edges, weights=weights0, density=True)\n",
    "    hist1, _ = np.histogram(data1, bins=bins_edges, weights=weights1, density=True)\n",
    "    \n",
    "    # Calculate intersection area (approximate integration)\n",
    "    bin_width = bins_edges[1] - bins_edges[0]\n",
    "    overlap_area = np.sum(np.minimum(hist0, hist1)) * bin_width\n",
    "    return overlap_area\n",
    "\n",
    "# Prepare Data\n",
    "ps_control = df_final[df_final['contrast_received']==0]['ps']\n",
    "w_control = df_final[df_final['contrast_received']==0]['iptw']\n",
    "ps_treated = df_final[df_final['contrast_received']==1]['ps']\n",
    "w_treated = df_final[df_final['contrast_received']==1]['iptw']\n",
    "\n",
    "# Calculate Metrics\n",
    "overlap_score = calculate_overlap_coefficient(ps_control, ps_treated, w_control, w_treated)\n",
    "\n",
    "print(f\"\\n--- EQUIPOISE DIAGNOSTICS ---\")\n",
    "print(f\"Distribution Overlap Coefficient: {overlap_score:.3f} (0=Separated, 1=Perfect Match)\")\n",
    "if overlap_score < 0.1:\n",
    "    print(\"WARNING: Poor overlap. Estimates relies heavily on extrapolation.\")\n",
    "elif overlap_score > 0.5:\n",
    "    print(\"SUCCESS: Strong clinical equipoise between groups.\")\n",
    "\n",
    "# --- PLOT ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot 1: Unweighted (Raw Propensity)\n",
    "# We use x=... explicitly here too for consistency\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.kdeplot(x=ps_control, fill=True, label='Withheld (Raw)', color='blue', alpha=0.3)\n",
    "sns.kdeplot(x=ps_treated, fill=True, label='Received (Raw)', color='red', alpha=0.3)\n",
    "plt.title(\"Before Weighting: Selection Bias\")\n",
    "plt.xlabel(\"Propensity Score\")\n",
    "plt.legend(loc='upper center')\n",
    "\n",
    "# Plot 2: Weighted (Pseudo-Population)\n",
    "# FIX: Added 'x=' before ps_control and ps_treated\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.kdeplot(x=ps_control, weights=w_control, fill=True, label='Withheld (Weighted)', color='blue', alpha=0.3)\n",
    "sns.kdeplot(x=ps_treated, weights=w_treated, fill=True, label='Received (Weighted)', color='red', alpha=0.3)\n",
    "plt.title(f\"After Weighting: Pseudo-Population\\nOverlap Coeff: {overlap_score:.2f}\")\n",
    "plt.xlabel(\"Propensity Score\")\n",
    "plt.legend(loc='upper center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8e5b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NEW DIAGNOSTIC CELL: Comprehensive Structural Positivity Test ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Running Comprehensive Structural Positivity Test...\")\n",
    "\n",
    "# 1. Define the Full Sets (From your provided list)\n",
    "CONTRAST_CT = {4139745, 21492176, 4335400, 3047782, 4327032, 3013610, 36713226, 3053128, 4252907, 3019625}\n",
    "CONTRAST_MRI = {4335399, 4161393, 4202274, 4197203, 36717294, 45765683, 37117806, 37109194, 37109196}\n",
    "NON_CONTRAST_CT = {37109313, 3049940, 37117305, 3047921, 36713200, 3018999, 40771605, 36713202, 3035568}\n",
    "NON_CONTRAST_MRI = {37109312, 36713204, 36713045, 36713262, 3024397, 36713243, 3053040, 37109329, 42535581, 42535582}\n",
    "\n",
    "# 2. Map Every ID to a Human-Readable Label & Category\n",
    "# We create a lookup dictionary for plotting\n",
    "proc_meta = {}\n",
    "\n",
    "def classify_proc(pid):\n",
    "    if pid in CONTRAST_CT: return 'CT (Contrast)', f\"CT_Con_{pid}\"\n",
    "    if pid in NON_CONTRAST_CT: return 'CT (Withheld)', f\"CT_Non_{pid}\"\n",
    "    if pid in CONTRAST_MRI: return 'MRI (Contrast)', f\"MRI_Con_{pid}\"\n",
    "    if pid in NON_CONTRAST_MRI: return 'MRI (Withheld)', f\"MRI_Non_{pid}\"\n",
    "    return 'Other', str(pid)\n",
    "\n",
    "# Apply to the dataframe\n",
    "df_viz = df_final.copy()\n",
    "# Apply classification row-wise (vectorized map is faster if we pre-calculate)\n",
    "# Since we have sets, we can do this efficiently:\n",
    "df_viz['modality_group'] = 'Other'\n",
    "df_viz.loc[df_viz['procedure_concept_id'].isin(CONTRAST_CT), 'modality_group'] = 'CT (Contrast)'\n",
    "df_viz.loc[df_viz['procedure_concept_id'].isin(NON_CONTRAST_CT), 'modality_group'] = 'CT (Withheld)'\n",
    "df_viz.loc[df_viz['procedure_concept_id'].isin(CONTRAST_MRI), 'modality_group'] = 'MRI (Contrast)'\n",
    "df_viz.loc[df_viz['procedure_concept_id'].isin(NON_CONTRAST_MRI), 'modality_group'] = 'MRI (Withheld)'\n",
    "\n",
    "df_viz['proc_label'] = df_viz['procedure_concept_id'].astype(str)\n",
    "\n",
    "# 3. VIZ 1: The Macro View (Modality Overlap)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(data=df_viz, x='modality_group', y='ps', palette=\"muted\", inner=\"quartile\")\n",
    "plt.title(\"Macro Check: Propensity Score by Modality & Status\")\n",
    "plt.ylabel(\"Propensity Score (Prob. of Contrast)\")\n",
    "plt.xlabel(\"Modality Group\")\n",
    "plt.axhline(0.5, color='gray', linestyle=':')\n",
    "plt.show()\n",
    "\n",
    "# 4. VIZ 2: The Micro View (All Procedures Sorted)\n",
    "# We calculate the median PS for each procedure to sort them\n",
    "proc_stats = df_viz.groupby('procedure_concept_id')['ps'].median().sort_values()\n",
    "sorted_procs = proc_stats.index.astype(str).tolist()\n",
    "\n",
    "# Split into CT and MRI for readability\n",
    "ct_ids = [str(x) for x in CONTRAST_CT.union(NON_CONTRAST_CT)]\n",
    "mri_ids = [str(x) for x in CONTRAST_MRI.union(NON_CONTRAST_MRI)]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 14), sharey=True)\n",
    "\n",
    "# Plot CT\n",
    "sns.boxplot(\n",
    "    data=df_viz[df_viz['proc_label'].isin(ct_ids)], \n",
    "    x='proc_label', y='ps', hue='contrast_received',\n",
    "    order=[p for p in sorted_procs if p in ct_ids],\n",
    "    ax=axes[0], palette={0:'blue', 1:'red'}, showfliers=False\n",
    ")\n",
    "axes[0].set_title(\"CT Procedures: Propensity Distribution (Sorted by Median PS)\")\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=90)\n",
    "axes[0].grid(True, axis='y', alpha=0.3)\n",
    "axes[0].legend(loc='upper left', title='Treatment')\n",
    "\n",
    "# Plot MRI\n",
    "sns.boxplot(\n",
    "    data=df_viz[df_viz['proc_label'].isin(mri_ids)], \n",
    "    x='proc_label', y='ps', hue='contrast_received',\n",
    "    order=[p for p in sorted_procs if p in mri_ids],\n",
    "    ax=axes[1], palette={0:'blue', 1:'red'}, showfliers=False\n",
    ")\n",
    "axes[1].set_title(\"MRI Procedures: Propensity Distribution (Sorted by Median PS)\")\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=90)\n",
    "axes[1].grid(True, axis='y', alpha=0.3)\n",
    "axes[1].get_legend().remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. The \"Red Flag\" Report\n",
    "print(\"\\n--- STRUCTURAL ZERO WARNINGS ---\")\n",
    "print(\"Identifying procedures with extreme Propensity Scores (PS < 0.10 or PS > 0.90)\")\n",
    "print(\"These indicate Protocol-Based decisions (Bias) rather than Clinical-Based decisions (Confounding).\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "low_ps = proc_stats[proc_stats < 0.10]\n",
    "high_ps = proc_stats[proc_stats > 0.90]\n",
    "\n",
    "if len(low_ps) > 0:\n",
    "    print(f\"âš ï¸  PROTOCOL EXCLUSION (Almost Never Get Contrast): {len(low_ps)} procedures\")\n",
    "    print(f\"    IDs: {low_ps.index.tolist()}\")\n",
    "    print(\"    -> These likely represent non-contrast protocols (e.g., C-Spine, Stroke, Stones).\")\n",
    "else:\n",
    "    print(\"âœ…  No extreme 'Never Contrast' protocols found (Median PS > 0.10).\")\n",
    "\n",
    "if len(high_ps) > 0:\n",
    "    print(f\"âš ï¸  PROTOCOL INCLUSION (Almost Always Get Contrast): {len(high_ps)} procedures\")\n",
    "    print(f\"    IDs: {high_ps.index.tolist()}\")\n",
    "    print(\"    -> These likely represent obligatory contrast protocols (e.g., Tumor Staging, Angio).\")\n",
    "else:\n",
    "    print(\"âœ…  No extreme 'Always Contrast' protocols found (Median PS < 0.90).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e27c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 8: LOVE PLOT ---\n",
    "\n",
    "def get_smd(X, t, w):\n",
    "    # Weighted Means\n",
    "    mu_1, var_1 = sparse_weighted_mean_var(X[t==1], w[t==1])\n",
    "    mu_0, var_0 = sparse_weighted_mean_var(X[t==0], w[t==0])\n",
    "    \n",
    "    # Pooled SD\n",
    "    pooled_sd = np.sqrt((var_1 + var_0) / 2)\n",
    "    pooled_sd[pooled_sd == 0] = 1e-6 # Avoid div/0\n",
    "    \n",
    "    return np.abs((mu_1 - mu_0) / pooled_sd)\n",
    "\n",
    "print(\"Calculating Balance...\")\n",
    "# Unweighted\n",
    "smd_unw = get_smd(X_final, T_final, np.ones(len(T_final)))\n",
    "# Weighted\n",
    "smd_w = get_smd(X_final, T_final, df_final['iptw'].values)\n",
    "\n",
    "# Plot top 50 imbalanced features\n",
    "top_idx = np.argsort(smd_unw)[-50:]\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.scatter(smd_unw[top_idx], range(50), label='Unadjusted', alpha=0.6)\n",
    "plt.scatter(smd_w[top_idx], range(50), label='Adjusted', alpha=0.8)\n",
    "plt.axvline(0.1, color='r', linestyle='--')\n",
    "plt.title(\"Covariate Balance (Top 50 Variates)\")\n",
    "plt.xlabel(\"Absolute SMD\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3fc66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: Cross-Fitted SuperLearner AIPW Engine (Sklearn Stacking)\n",
    "# =============================================================================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "print(\"\\n--- CELL 9: Super Learner AIPW Engine (Sklearn Stacking) ---\")\n",
    "\n",
    "def calculate_e_value(rr_or_hr):\n",
    "    \"\"\"Calculates E-Value for unmeasured confounding.\"\"\"\n",
    "    if rr_or_hr <= 1: return 1\n",
    "    return rr_or_hr + np.sqrt(rr_or_hr * (rr_or_hr - 1))\n",
    "\n",
    "def get_super_learner(n_jobs_inner=1):\n",
    "    \"\"\"\n",
    "    Returns an sklearn StackingClassifier designed for sparse data.\n",
    "    Combines:\n",
    "      1. Lasso (Linear, good for rare codes)\n",
    "      2. Random Forest (Non-linear, good for interactions)\n",
    "    \"\"\"\n",
    "    # 1. Base Learners\n",
    "    # We use 'liblinear' for Lasso as it handles sparse matrices efficiently.\n",
    "    # We limit RF depth slightly to prevent memory explosion with 70k features.\n",
    "    estimators = [\n",
    "        ('lasso', LogisticRegression(penalty='l1', solver='liblinear', C=0.2, \n",
    "                                     class_weight='balanced', max_iter=2000)),\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, max_depth=20, \n",
    "                                      class_weight='balanced', n_jobs=n_jobs_inner))\n",
    "    ]\n",
    "    \n",
    "    # 2. The Stack (Meta-Learner)\n",
    "    # Uses internal CV to learn how to best combine Lasso and RF predictions\n",
    "    # passthrough=False means the meta-learner only sees the predictions of base learners\n",
    "    stack = StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=LogisticRegression(), \n",
    "        cv=3,  # Internal 3-fold CV to train the combiner\n",
    "        n_jobs=n_jobs_inner,\n",
    "        passthrough=False\n",
    "    )\n",
    "    return stack\n",
    "\n",
    "def _fit_super_learner_fold(train_idx, eval_idx, X_sparse, T_full, Y_full):\n",
    "    \"\"\"\n",
    "    Worker function for a single fold of Cross-Fitting.\n",
    "    Fits the Super Learner on training data, predicts on eval data.\n",
    "    \"\"\"\n",
    "    # 1. Slice Data (Sparse Slicing)\n",
    "    X_train, X_eval = X_sparse[train_idx], X_sparse[eval_idx]\n",
    "    T_train, T_eval = T_full[train_idx], T_full[eval_idx]\n",
    "    Y_train, Y_eval = Y_full[train_idx], Y_full[eval_idx]\n",
    "    \n",
    "    # Note: We use n_jobs_inner=4 for models to speed up RF training inside the fold.\n",
    "    # Total threads = n_folds (outer) * n_jobs_inner.\n",
    "    \n",
    "    # --- 2. Propensity Score Model (Pi) ---\n",
    "    sl_ps = get_super_learner(n_jobs_inner=4)\n",
    "    sl_ps.fit(X_train, T_train)\n",
    "    pi_hat = sl_ps.predict_proba(X_eval)[:, 1]\n",
    "    # Clip for stability (AIPW requirement)\n",
    "    pi_hat = np.clip(pi_hat, 0.025, 0.975)\n",
    "    \n",
    "    # --- 3. Outcome Models (Mu) ---\n",
    "    # We must separate T=0 and T=1 to learn the counterfactuals\n",
    "    mask0 = (T_train == 0)\n",
    "    mask1 = (T_train == 1)\n",
    "    \n",
    "    # Mu0 (Outcome if No Contrast)\n",
    "    sl_mu0 = get_super_learner(n_jobs_inner=4)\n",
    "    sl_mu0.fit(X_train[mask0], Y_train[mask0])\n",
    "    mu0_hat = sl_mu0.predict_proba(X_eval)[:, 1]\n",
    "    \n",
    "    # Mu1 (Outcome if Contrast)\n",
    "    sl_mu1 = get_super_learner(n_jobs_inner=4)\n",
    "    sl_mu1.fit(X_train[mask1], Y_train[mask1])\n",
    "    mu1_hat = sl_mu1.predict_proba(X_eval)[:, 1]\n",
    "    \n",
    "    # --- 4. Compute Efficient Influence Function (EIF) ---\n",
    "    # Formula: (mu1 - mu0) + T(Y-mu1)/pi - (1-T)(Y-mu0)/(1-pi)\n",
    "    term1 = mu1_hat - mu0_hat # Risk Difference\n",
    "    term2 = (T_eval * (Y_eval - mu1_hat)) / pi_hat\n",
    "    term3 = ((1 - T_eval) * (Y_eval - mu0_hat)) / (1 - pi_hat)\n",
    "    eif_chunk = term1 + term2 - term3\n",
    "    \n",
    "    return eval_idx, mu0_hat, mu1_hat, pi_hat, eif_chunk\n",
    "\n",
    "def run_cross_fitted_aipw(X_sparse_matrix, T_full, Y_full, n_folds=5):\n",
    "    \"\"\"\n",
    "    Main driver for K-Fold Cross-Fitting.\n",
    "    Returns: stats (dict), predictions (dict)\n",
    "    \"\"\"\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    n = len(T_full)\n",
    "    \n",
    "    # Storage arrays\n",
    "    mu0_hat = np.zeros(n)\n",
    "    mu1_hat = np.zeros(n)\n",
    "    pi_hat  = np.zeros(n)\n",
    "    eif_val = np.zeros(n)\n",
    "    \n",
    "    print(f\"  Running {n_folds}-Fold Super Learner (StackingClassifier) in PARALLEL...\")\n",
    "    print(f\"  (This utilizes high compute: Lasso + Random Forest Stacking)\")\n",
    "\n",
    "    # --- Parallel Execution ---\n",
    "    # Runs the 5 folds simultaneously.\n",
    "    results = Parallel(n_jobs=n_folds, verbose=10)(\n",
    "        delayed(_fit_super_learner_fold)(train_idx, eval_idx, X_sparse_matrix, T_full, Y_full)\n",
    "        for train_idx, eval_idx in kf.split(X_sparse_matrix, T_full)\n",
    "    )\n",
    "    \n",
    "    # --- Aggregate Results ---\n",
    "    for eval_idx, mu0_c, mu1_c, pi_c, eif_c in results:\n",
    "        mu0_hat[eval_idx] = mu0_c\n",
    "        mu1_hat[eval_idx] = mu1_c\n",
    "        pi_hat[eval_idx]  = pi_c\n",
    "        eif_val[eval_idx] = eif_c\n",
    "\n",
    "    # --- Statistics & Inference ---\n",
    "    ate = np.mean(eif_val)\n",
    "    se = np.std(eif_val) / np.sqrt(n)\n",
    "    # Z-test P-value\n",
    "    p_value = 2 * (1 - norm.cdf(np.abs(ate / se))) if se > 0 else 0.0\n",
    "    \n",
    "    # Risk Estimates (Population Averages)\n",
    "    risk_1 = np.mean(mu1_hat)\n",
    "    risk_0 = np.mean(mu0_hat)\n",
    "    rr = risk_1 / risk_0 if risk_0 > 0 else 0.0\n",
    "    \n",
    "    # Effective Sample Size (Kish)\n",
    "    weights = np.where(T_full==1, 1/pi_hat, 1/(1-pi_hat))\n",
    "    ess = (np.sum(weights) ** 2) / np.sum(weights ** 2)\n",
    "    \n",
    "    # E-Value Calculation\n",
    "    # Maps RR < 1 to equivalent risk increase for formula\n",
    "    e_calc_rr = 1/rr if (rr < 1 and rr > 0) else rr\n",
    "    e_val = calculate_e_value(e_calc_rr) if not np.isnan(rr) else 1.0\n",
    "\n",
    "    stats = {\n",
    "        'ATE': ate, 'SE': se, 'P_Value': p_value,\n",
    "        'Risk_1': risk_1, 'Risk_0': risk_0, \n",
    "        'RR': rr, 'ESS': ess, 'E_Value': e_val,\n",
    "        'CI_Lower': ate - 1.96*se, 'CI_Upper': ate + 1.96*se\n",
    "    }\n",
    "    \n",
    "    predictions = {\n",
    "        'mu0': mu0_hat, 'mu1': mu1_hat, 'pi': pi_hat, 'eif': eif_val\n",
    "    }\n",
    "    \n",
    "    return stats, predictions\n",
    "\n",
    "print(\"Super Learner Engine (Sklearn) Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dd3277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define Policies\n",
    "# Policies act on the 'df_final' cohort (covariates) to output a decision vector d âˆˆ {0, 1}^n\n",
    "# 0 = Withhold all contrast, 1 = Give contrast\n",
    "#\n",
    "# NOTE: ACR 2024 guidance is about *which* contrast (iodinated vs GBCA),\n",
    "# not \"withhold vs give\". The eGFR-based rules below are *toy* withholding\n",
    "# rules for counterfactual exploration, not literal guideline implementations.\n",
    "\n",
    "def policy_current(df):\n",
    "    \"\"\"Current Practice: The observed decision.\"\"\"\n",
    "    return df['contrast_received'].values\n",
    "\n",
    "def policy_always(df):\n",
    "    \"\"\"Extreme policy: Always give contrast (100% contrast use).\"\"\"\n",
    "    return np.ones(len(df), dtype=int)\n",
    "\n",
    "def policy_never(df):\n",
    "    \"\"\"Extreme policy: Never give contrast (0% contrast use).\"\"\"\n",
    "    return np.zeros(len(df), dtype=int)\n",
    "\n",
    "def policy_egfr_rule_30(df):\n",
    "    \"\"\"Toy rule: Withhold contrast if eGFR < 30 (egfr_cat == 0), otherwise give.\"\"\"\n",
    "    return (df['egfr_cat'] != 0).astype(int).values\n",
    "\n",
    "def policy_egfr_rule_45(df):\n",
    "    \"\"\"Toy rule: Withhold contrast if eGFR < 45 (egfr_cat in {0,1}), otherwise give.\"\"\"\n",
    "    return (~df['egfr_cat'].isin([0, 1])).astype(int).values\n",
    "\n",
    "policies = {\n",
    "    'Current Practice': policy_current,\n",
    "    'Always Contrast (100%)': policy_always,\n",
    "    'Never Contrast (0%)': policy_never,\n",
    "    'eGFR Rule: withhold if <30': policy_egfr_rule_30,\n",
    "    'eGFR Rule: withhold if <45': policy_egfr_rule_45,\n",
    "}\n",
    "\n",
    "\n",
    "# 2. Execution Loop\n",
    "# We evaluate on the primary outcome (AKI_30)\n",
    "outcome_name = 'AKI_30'\n",
    "col_date = f\"date_{outcome_name}\"\n",
    "print(f\"Evaluating policies for outcome: {outcome_name}\")\n",
    "\n",
    "# Prepare Arrays\n",
    "T_vec = df_final['contrast_received'].values\n",
    "# Define Y (Binary outcome within 30 days)\n",
    "Y_vec = ((df_final[col_date] - df_final['index_date']).dt.days <= 30).astype(int).values\n",
    "\n",
    "# Step A: Get Nuisance Parameters (Mu0, Mu1, Pi) via Cross-Fitting\n",
    "# We use the X_final sparse matrix\n",
    "stats, preds = run_cross_fitted_aipw(X_final, T_vec, Y_vec, n_folds=5)\n",
    "\n",
    "mu1 = preds['mu1']\n",
    "mu0 = preds['mu0']\n",
    "pi  = preds['pi']\n",
    "\n",
    "# Step B: Evaluate Policies\n",
    "policy_results = []\n",
    "\n",
    "for name, func in policies.items():\n",
    "    d_vec = func(df_final) # 0/1 vector\n",
    "    \n",
    "    # Calculate Policy Value V(d) using AIPW (Doubly Robust) estimator adapted for policies\n",
    "    # V_dr(d) = Mean( d/pi * (Y - mu1) + mu1 ) if d=1, ... logic generalizes:\n",
    "    # Estimate Y(1) for everyone, Y(0) for everyone, then mix based on d.\n",
    "    # DR Score for individual i:\n",
    "    # Gamma_1 = mu1 + T/pi * (Y - mu1)\n",
    "    # Gamma_0 = mu0 + (1-T)/(1-pi) * (Y - mu0)\n",
    "    # V(d) = d * Gamma_1 + (1-d) * Gamma_0\n",
    "    \n",
    "    gamma_1 = mu1 + (T_vec / pi) * (Y_vec - mu1)\n",
    "    gamma_0 = mu0 + ((1 - T_vec) / (1 - pi)) * (Y_vec - mu0)\n",
    "    \n",
    "    # Individual policy estimates\n",
    "    psi_i = d_vec * gamma_1 + (1 - d_vec) * gamma_0\n",
    "    \n",
    "    risk_val = np.mean(psi_i)\n",
    "    risk_se  = np.std(psi_i) / np.sqrt(len(psi_i))\n",
    "    \n",
    "    # Withholding Rate (W)\n",
    "    withhold_rate = np.mean(1 - d_vec)\n",
    "    \n",
    "    policy_results.append({\n",
    "        'Policy': name,\n",
    "        'Risk': risk_val,\n",
    "        'Risk_SE': risk_se,\n",
    "        'Withholding': withhold_rate\n",
    "    })\n",
    "\n",
    "df_pol_res = pd.DataFrame(policy_results)\n",
    "print(df_pol_res.round(5))\n",
    "\n",
    "# 3. Visualization (XY Plot)\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Plot points with error bars\n",
    "for i, row in df_pol_res.iterrows():\n",
    "    plt.errorbar(\n",
    "        x=row['Withholding'],\n",
    "        y=row['Risk'],\n",
    "        yerr=1.96 * row['Risk_SE'],\n",
    "        fmt='o',\n",
    "        markersize=10,\n",
    "        capsize=5,\n",
    "        label=row['Policy']\n",
    "    )\n",
    "    # Label text offset\n",
    "    plt.text(row['Withholding'], row['Risk'] + 0.0005, f\"  {row['Policy']}\", fontsize=9)\n",
    "\n",
    "# Formatting\n",
    "plt.title(f\"Policy Frontier: Harm vs. Withholding\\nOutcome: {outcome_name} (30-Day Risk)\")\n",
    "plt.xlabel(\"Proportion of Patients Withheld Contrast\")\n",
    "plt.ylabel(f\"Estimated Risk of {outcome_name}\")\n",
    "plt.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Print AIPW stats for the contrast vs no-contrast comparison\n",
    "print(f\"ATE (Contrast vs No-Contrast): {stats['ATE']:.4f} \"\n",
    "      f\"[{stats['CI_Lower']:.4f}, {stats['CI_Upper']:.4f}], p={stats['P_Value']:.3g}\")\n",
    "print(f\"Risk_1 (E[Y | do(T=1)]): {stats['Risk_1']:.4f}\")\n",
    "print(f\"Risk_0 (E[Y | do(T=0)]): {stats['Risk_0']:.4f}\")\n",
    "print(f\"RR (Contrast vs No-Contrast): {stats['RR']:.3f}\")\n",
    "print(f\"E-Value (Contrast vs No-Contrast): {stats['E_Value']:.2f}\")\n",
    "print(f\"AIPW Effective Sample Size (AIPW weights): {stats['ESS']:.1f}\")\n",
    "\n",
    "# Current-practice policy value from the policy frontier\n",
    "cp_row = df_pol_res[df_pol_res['Policy'] == 'Current Practice'].iloc[0]\n",
    "print(f\"Current Practice Policy Risk (DR): {cp_row['Risk']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8114b150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 11: SURVIVAL PLOTS ---\n",
    "\n",
    "outcome = 'AKI_30'\n",
    "print(f\"Diagnostic Plots for {outcome} (Observed Trial)...\")\n",
    "\n",
    "df_viz = df_final.copy()\n",
    "\n",
    "# Time-to-event for AKI within 30 days\n",
    "event_date = df_viz['date_AKI_30']\n",
    "idx_date = df_viz['index_date']\n",
    "\n",
    "# If no event, censor at 30 days\n",
    "event_date_filled = event_date.fillna(idx_date + pd.Timedelta(days=30))\n",
    "t_days = (event_date_filled - idx_date).dt.days\n",
    "t_days = t_days.clip(lower=0, upper=30)\n",
    "\n",
    "df_viz['T_viz'] = t_days\n",
    "df_viz['E_viz'] = ((event_date.notnull()) &\n",
    "                   ((event_date - idx_date).dt.days <= 30)).astype(int)\n",
    "\n",
    "# 1. KM Curves with IPTW\n",
    "kmf0 = KaplanMeierFitter()\n",
    "kmf1 = KaplanMeierFitter()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "kmf0.fit(\n",
    "    df_viz[df_viz['contrast_received'] == 0]['T_viz'],\n",
    "    df_viz[df_viz['contrast_received'] == 0]['E_viz'],\n",
    "    weights=df_viz[df_viz['contrast_received'] == 0]['iptw'],\n",
    "    label='Withheld'\n",
    ")\n",
    "kmf1.fit(\n",
    "    df_viz[df_viz['contrast_received'] == 1]['T_viz'],\n",
    "    df_viz[df_viz['contrast_received'] == 1]['E_viz'],\n",
    "    weights=df_viz[df_viz['contrast_received'] == 1]['iptw'],\n",
    "    label='Contrast'\n",
    ")\n",
    "\n",
    "kmf0.plot_survival_function()\n",
    "kmf1.plot_survival_function()\n",
    "plt.title(f\"Adjusted Survival Curve: {outcome}\")\n",
    "plt.xlabel(\"Days since index\")\n",
    "plt.ylabel(\"Survival probability (no AKI)\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Cox model & PH diagnostics\n",
    "cph = CoxPHFitter(penalizer=0.1)\n",
    "cph.fit(\n",
    "    df_viz[['T_viz', 'E_viz', 'contrast_received', 'iptw']],\n",
    "    duration_col='T_viz',\n",
    "    event_col='E_viz',\n",
    "    weights_col='iptw'\n",
    ")\n",
    "cph.check_assumptions(\n",
    "    df_viz[['T_viz', 'E_viz', 'contrast_received', 'iptw']],\n",
    "    show_plots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd398410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 12: ECOLOGICAL CONFOUNDING CHECK (CORRECTED) ---\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\n--- ECOLOGICAL ANALYSIS (INSTRUMENTAL VARIABLE CHECK) ---\")\n",
    "\n",
    "# 1. Aggregate by Site (Zip)\n",
    "site_stats = df_final.groupby('zip_code').agg({\n",
    "    'contrast_received': 'mean', # Observed Rate\n",
    "    'ps': 'mean',                # Expected Rate (Patient Risk Profile)\n",
    "    'iptw': 'count'              # Volume\n",
    "}).rename(columns={'iptw': 'volume'})\n",
    "\n",
    "# Filter for meaningful sites (e.g., >20 patients)\n",
    "site_stats = site_stats[site_stats['volume'] > 20].copy()\n",
    "\n",
    "# 2. Calculate \"Practice Preference\" (Instrument)\n",
    "site_stats['practice_preference'] = site_stats['contrast_received'] - site_stats['ps']\n",
    "\n",
    "# 3. Calculate Site-Level Outcome Rate (Raw)\n",
    "aki_events = ((df_final['date_AKI_30'] - df_final['index_date']).dt.days <= 30)\n",
    "df_final['has_aki_30'] = aki_events.fillna(False).astype(int)\n",
    "outcome_stats = df_final.groupby('zip_code')['has_aki_30'].mean()\n",
    "\n",
    "eco_df = site_stats.merge(outcome_stats, left_index=True, right_index=True)\n",
    "\n",
    "# --- FIX: Convert to standard numpy floats to prevent Seaborn TypeError ---\n",
    "eco_df['practice_preference'] = eco_df['practice_preference'].astype(float)\n",
    "eco_df['has_aki_30'] = eco_df['has_aki_30'].astype(float)\n",
    "eco_df['volume'] = eco_df['volume'].astype(float)\n",
    "\n",
    "# 4. Correlation Test\n",
    "corr, p_val = pearsonr(eco_df['practice_preference'], eco_df['has_aki_30'])\n",
    "\n",
    "print(f\"Number of Sites Analyzed: {len(eco_df)}\")\n",
    "print(f\"Correlation (r): {corr:.3f}\")\n",
    "print(f\"P-Value: {p_val:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_val < 0.05 and abs(corr) > 0.2:\n",
    "    print(\"WARNING: Significant Ecological Correlation detected.\")\n",
    "    print(\"This suggests Unmeasured Confounding at the site level.\")\n",
    "else:\n",
    "    print(\"PASS: No significant correlation between site preference and outcomes.\")\n",
    "    print(\"Variation in withholding appears random regarding unmeasured site quality.\")\n",
    "\n",
    "# 5. The Quadrant Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    data=eco_df, \n",
    "    x='practice_preference', \n",
    "    y='has_aki_30', \n",
    "    size='volume', \n",
    "    sizes=(20, 600),\n",
    "    alpha=0.6,\n",
    "    hue='practice_preference',\n",
    "    palette='vlag'\n",
    ")\n",
    "\n",
    "# Add Quadrant Lines\n",
    "mean_pref = eco_df['practice_preference'].mean()\n",
    "mean_out = eco_df['has_aki_30'].mean()\n",
    "plt.axhline(mean_out, linestyle='--', color='gray', alpha=0.7)\n",
    "plt.axvline(mean_pref, linestyle='--', color='gray', alpha=0.7)\n",
    "\n",
    "# Labels\n",
    "plt.title(\"Ecological Analysis: Site Preference vs. Outcomes\")\n",
    "plt.xlabel(\"Site Preference (Actual - Expected)\\n<-- Conservative (Withholds) | Aggressive (Gives) -->\")\n",
    "plt.ylabel(\"Raw AKI Rate (30-Day)\")\n",
    "\n",
    "# Quadrant Annotations\n",
    "plt.text(mean_pref + 0.02, mean_out - 0.005, \"Aggressive & Low Risk\", color='green', fontsize=9)\n",
    "plt.text(mean_pref - 0.08, mean_out + 0.005, \"Conservative & High Risk\", color='red', fontsize=9)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title=\"Preference\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dc3006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 10.5: RISK-BASED CONFOUNDING-BY-INDICATION CHECK ---\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "print(\"\\n--- RISK-BASED CONFOUNDING CHECK (mu0 vs Treatment/Propensity) ---\")\n",
    "\n",
    "# Assemble diagnostic frame\n",
    "df_diag = pd.DataFrame({\n",
    "    \"mu_0\": preds[\"mu0\"],           # Estimated risk if untreated\n",
    "    \"mu_1\": preds[\"mu1\"],           # Estimated risk if treated\n",
    "    \"pi\": preds[\"pi\"],              # Propensity score from nuisance model\n",
    "    \"contrast_received\": T_vec      # Actual treatment (0/1)\n",
    "}, index=df_final.index)\n",
    "\n",
    "# 1. Correlation: baseline risk vs propensity score\n",
    "mask_pi = df_diag[\"mu_0\"].notna() & df_diag[\"pi\"].notna()\n",
    "r_mu0_pi, p_mu0_pi = pearsonr(\n",
    "    df_diag.loc[mask_pi, \"mu_0\"],\n",
    "    df_diag.loc[mask_pi, \"pi\"]\n",
    ")\n",
    "\n",
    "# 2. Correlation: baseline risk vs observed treatment\n",
    "mask_t = df_diag[\"mu_0\"].notna() & df_diag[\"contrast_received\"].notna()\n",
    "r_mu0_t, p_mu0_t = pearsonr(\n",
    "    df_diag.loc[mask_t, \"mu_0\"],\n",
    "    df_diag.loc[mask_t, \"contrast_received\"]\n",
    ")\n",
    "\n",
    "print(f\"Corr(mu_0, pi):               r = {r_mu0_pi:.3f}, p = {p_mu0_pi:.2e}\")\n",
    "print(f\"Corr(mu_0, contrast_received): r = {r_mu0_t:.3f}, p = {p_mu0_t:.2e}\")\n",
    "\n",
    "if (r_mu0_pi < -0.2 and p_mu0_pi < 0.05) or (r_mu0_t < -0.2 and p_mu0_t < 0.05):\n",
    "    print(\"SIGNAL: Higher baseline risk associated with lower treatment probability (confounding by indication).\")\n",
    "else:\n",
    "    print(\"NO STRONG SIGNAL: Baseline risk not clearly linked to treatment probability.\")\n",
    "\n",
    "# 3. Visualization: Baseline risk vs propensity\n",
    "sample_df = df_diag.sample(n=min(10000, len(df_diag)), random_state=42)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    data=sample_df,\n",
    "    x=\"mu_0\",\n",
    "    y=\"pi\",\n",
    "    hue=\"contrast_received\",\n",
    "    alpha=0.3,\n",
    "    s=20\n",
    ")\n",
    "sns.regplot(\n",
    "    data=sample_df,\n",
    "    x=\"mu_0\",\n",
    "    y=\"pi\",\n",
    "    scatter=False,\n",
    "    lowess=True\n",
    ")\n",
    "\n",
    "plt.title(\"Baseline Risk vs Propensity to Receive Contrast\")\n",
    "plt.xlabel(\"Estimated Risk if Untreated (mu_0)\")\n",
    "plt.ylabel(\"Propensity Score (pi)\")\n",
    "plt.legend(title=\"Contrast Received\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac05db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 13: Method Validation (Negative Controls) & Calibration\n",
    "# =============================================================================\n",
    "print(\"\\n--- CELL 13: Negative Control Validation ---\")\n",
    "\n",
    "nc_res_list = []\n",
    "\n",
    "# Loop through Negative Controls\n",
    "for nc_name in NEGATIVE_CONTROLS.keys():\n",
    "    col_nc = f\"date_{nc_name}\"\n",
    "    if col_nc not in df_final.columns: continue\n",
    "    \n",
    "    # Define Y_nc\n",
    "    Y_nc = ((df_final[col_nc] - df_final['index_date']).dt.days <= 30).astype(int).values\n",
    "    T_nc = df_final['contrast_received'].values\n",
    "    \n",
    "    # Run simplified AIPW (or just weighted Reg for speed)\n",
    "    # We use Weighted Logistic Regression here for speed/stability on NCs\n",
    "    try:\n",
    "        # Unadjusted\n",
    "        lr_unadj = LogisticRegression(solver='lbfgs')\n",
    "        lr_unadj.fit(T_nc.reshape(-1, 1), Y_nc)\n",
    "        or_unadj = np.exp(lr_unadj.coef_[0][0])\n",
    "        \n",
    "        # Adjusted (Using IPTW from Cell 7 if available, or just re-fit simple weights)\n",
    "        # We'll use the PS from the main model if available in df_final\n",
    "        if 'iptw' in df_final.columns:\n",
    "            weights = df_final['iptw'].values\n",
    "        else:\n",
    "            weights = np.ones_like(T_nc)\n",
    "            \n",
    "        lr_adj = LogisticRegression(solver='lbfgs')\n",
    "        lr_adj.fit(T_nc.reshape(-1, 1), Y_nc, sample_weight=weights)\n",
    "        or_adj = np.exp(lr_adj.coef_[0][0])\n",
    "        \n",
    "        # CI for Adjusted\n",
    "        # (Approximate SE via Inverse Hessian or bootstrap - skipping for speed in summary)\n",
    "        \n",
    "        nc_res_list.append({\n",
    "            'Outcome': nc_name,\n",
    "            'OR_Unadj': or_unadj,\n",
    "            'OR_Adj': or_adj,\n",
    "            'LogOR_Adj': lr_adj.coef_[0][0]\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {nc_name}: {e}\")\n",
    "\n",
    "df_nc = pd.DataFrame(nc_res_list)\n",
    "\n",
    "# Visualization: Calibration Funnel / Scatter\n",
    "if not df_nc.empty:\n",
    "    print(df_nc.round(3))\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot 1: Unadjusted vs Adjusted\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(np.log(df_nc['OR_Unadj']), np.log(df_nc['OR_Adj']), alpha=0.7, c='purple')\n",
    "    plt.axhline(0, color='black', linestyle='--')\n",
    "    plt.axvline(0, color='black', linestyle='--')\n",
    "    plt.plot([-2, 2], [-2, 2], 'k:', alpha=0.3)\n",
    "    plt.title(\"Bias Correction: Unadjusted vs Adjusted Estimates\")\n",
    "    plt.xlabel(\"Unadjusted Log OR\")\n",
    "    plt.ylabel(\"Adjusted Log OR\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot 2: Null Distribution\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(df_nc['LogOR_Adj'], kde=True, bins=10)\n",
    "    plt.axvline(0, color='red', linestyle='--', label='Null')\n",
    "    plt.title(\"Distribution of Negative Control Estimates (Should center at 0)\")\n",
    "    plt.xlabel(\"Adjusted Log OR\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary Metric\n",
    "    rmse = np.sqrt(np.mean(df_nc['LogOR_Adj']**2))\n",
    "    print(f\"Calibration RMSE (Distance from Null): {rmse:.4f}\")\n",
    "    if rmse < 0.1: print(\"VALIDATION: Excellent Calibration.\")\n",
    "    elif rmse < 0.2: print(\"VALIDATION: Acceptable Calibration.\")\n",
    "    else: print(\"VALIDATION: WARNING - Possible Residual Confounding.\")\n",
    "\n",
    "# Save Results\n",
    "if 'df_pol_res' in locals():\n",
    "    df_pol_res.to_csv(\"final_policy_results.csv\", index=False)\n",
    "    print(\"Saved final results to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425de29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NEW CELL: Subgroup Policy Analysis (eGFR Categories)\n",
    "# =============================================================================\n",
    "print(\"\\n--- NEW CELL: Subgroup Analysis by eGFR Category ---\")\n",
    "\n",
    "# Define Subgroups based on egfr_cat\n",
    "# 0=<30, 1=30-44, 2=45-59, 3=60+\n",
    "subgroups = {\n",
    "    'eGFR < 30': [0],\n",
    "    'eGFR 30-44': [1],\n",
    "    'eGFR 45-59': [2],\n",
    "    'eGFR >= 60': [3]\n",
    "}\n",
    "\n",
    "# We perform the analysis on the subsets\n",
    "# Note: For valid inference, we calculate risks WITHIN the subgroup\n",
    "# utilizing the predictions from the global model (Predictions are conditional on X)\n",
    "# V(d | S) = E[ Psi_i | i in S ]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plot_idx = 1\n",
    "for label, cats in subgroups.items():\n",
    "    # Identify Indices\n",
    "    mask = df_final['egfr_cat'].isin(cats)\n",
    "    indices = df_final[mask].index\n",
    "    \n",
    "    if len(indices) < 50:\n",
    "        print(f\"Skipping {label}: N={len(indices)} (Too small)\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"Analyzing Subgroup: {label} (N={len(indices)})\")\n",
    "    \n",
    "    # Filter global predictions (preds defined in Cell 10/9)\n",
    "    # We use the integer locations of the mask\n",
    "    locs = np.where(mask.values)[0]\n",
    "    \n",
    "    gamma_1_sub = preds['mu1'][locs] + (T_vec[locs]/preds['pi'][locs]) * (Y_vec[locs] - preds['mu1'][locs])\n",
    "    gamma_0_sub = preds['mu0'][locs] + ((1-T_vec[locs])/(1-preds['pi'][locs])) * (Y_vec[locs] - preds['mu0'][locs])\n",
    "    \n",
    "    # Evaluate Policies on this subgroup\n",
    "    res_sub = []\n",
    "    for pol_name, func in policies.items():\n",
    "        # Get decision for this subgroup\n",
    "        # We need to slice the dataframe for the function input\n",
    "        df_sub = df_final.iloc[locs]\n",
    "        d_sub = func(df_sub)\n",
    "        \n",
    "        # Calculate Value\n",
    "        psi_sub = d_sub * gamma_1_sub + (1 - d_sub) * gamma_0_sub\n",
    "        \n",
    "        risk = np.mean(psi_sub)\n",
    "        se = np.std(psi_sub) / np.sqrt(len(psi_sub))\n",
    "        withhold = np.mean(1 - d_sub)\n",
    "        \n",
    "        res_sub.append({'Policy': pol_name, 'Risk': risk, 'SE': se, 'W': withhold})\n",
    "        \n",
    "    df_res_sub = pd.DataFrame(res_sub)\n",
    "    \n",
    "    # Plot\n",
    "    plt.subplot(2, 2, plot_idx)\n",
    "    for i, row in df_res_sub.iterrows():\n",
    "        plt.errorbar(row['W'], row['Risk'], yerr=1.96*row['SE'], fmt='o', label=row['Policy'], capsize=5)\n",
    "        plt.text(row['W'], row['Risk'], f\" {row['Policy']}\", fontsize=8)\n",
    "        \n",
    "    plt.title(f\"Subgroup: {label}\")\n",
    "    plt.xlabel(\"Withholding Rate\")\n",
    "    plt.ylabel(f\"{outcome_name} Risk\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    if plot_idx == 1: plt.legend(loc='upper left', fontsize=8)\n",
    "    \n",
    "    plot_idx += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b179e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441e8694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
